"""
CGU MCP Server

ä½¿ç”¨ FastMCP æä¾›å‰µæ„ç”Ÿæˆå·¥å…·
æ•´åˆ Ollama LLM é€²è¡ŒçœŸå¯¦å‰µæ„ç”Ÿæˆ

æ”¯æ´ä¸‰ç¨®æ€è€ƒæ¨¡å¼ï¼š
- simple: Ollama/Copilot å¿«é€Ÿå–®æ¬¡ç™¼æƒ³ï¼ˆé è¨­ï¼‰
- deep: Multi-Agent ä¸¦ç™¼æ·±åº¦æ€è€ƒ
- spark: æ¦‚å¿µç¢°æ’ç”¢ç”Ÿéˆæ„Ÿç«èŠ±
"""

import os
import logging

from mcp.server.fastmcp import FastMCP

from cgu.core import (
    CreativityLevel,
    CreativityMethod,
    ThinkingMode,
    ThinkingSpeed,
    METHOD_CONFIGS,
    select_method_for_task,
)

# è¨­å®š logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# LLM æ¨¡å¼
# é è¨­ true - å•Ÿç”¨ Ollama LLMï¼ˆç¢ºä¿ Ollama æœå‹™å·²å•Ÿå‹•ï¼‰
USE_LLM = os.getenv("CGU_USE_LLM", "true").lower() == "true"
# æ€è€ƒå¼•æ“ï¼šollama (æœ¬åœ°æ¨ç†) | copilot (åƒ…æä¾›æ¡†æ¶ï¼Œè®“ Copilot å¡«å……)
LLM_PROVIDER = os.getenv("CGU_LLM_PROVIDER", "ollama").lower()
# æ€è€ƒæ·±åº¦ï¼šshallow (å¿«) | medium (ä¸­) | deep (æ·±)
THINKING_DEPTH = os.getenv("CGU_THINKING_DEPTH", "medium").lower()
# Ollama æ¨¡å‹
OLLAMA_MODEL = os.getenv("CGU_OLLAMA_MODEL", "qwen2.5:3b")

# åˆå§‹åŒ– FastMCP Server
mcp = FastMCP(
    name="creativity-generation-unit",
    instructions="CGU - MCP-based å‰µæ„ç™¼æƒ³æœå‹™ï¼Œä½¿ç”¨å¿«æ€æ…¢æƒ³æ¶æ§‹ã€‚æ”¯æ´ generate_ideas, spark_collision, apply_method ç­‰å·¥å…·ã€‚",
)


# === LLM è¼”åŠ©å‡½æ•¸ ===

def _get_llm_client():
    """å–å¾— LLM å®¢æˆ¶ç«¯"""
    # copilot æ¨¡å¼ï¼šä¸ä½¿ç”¨æœ¬åœ° LLMï¼Œè¿”å›æ¡†æ¶è®“ Copilot æ€è€ƒ
    if LLM_PROVIDER == "copilot":
        return None
    if not USE_LLM:
        return None
    try:
        from cgu.llm import get_llm_client, LLMConfig
        # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸é…ç½®
        config = LLMConfig(model=OLLAMA_MODEL)
        return get_llm_client(config)
    except Exception as e:
        logger.warning(f"LLM åˆå§‹åŒ–å¤±æ•—: {e}")
        logger.info("æç¤ºï¼šè«‹ç¢ºä¿ Ollama æœå‹™å·²å•Ÿå‹• (ollama serve)")
        return None


def _is_copilot_mode() -> bool:
    """æª¢æŸ¥æ˜¯å¦ç‚º Copilot æ¨¡å¼"""
    return LLM_PROVIDER == "copilot"


def _get_thinking_engine():
    """å–å¾—çµ±ä¸€æ€è€ƒå¼•æ“"""
    try:
        from cgu.thinking import ThinkingEngine, ThinkingConfig, ThinkingDepth

        depth_map = {
            "shallow": ThinkingDepth.SHALLOW,
            "medium": ThinkingDepth.MEDIUM,
            "deep": ThinkingDepth.DEEP,
        }

        config = ThinkingConfig(depth=depth_map.get(THINKING_DEPTH, ThinkingDepth.MEDIUM))
        engine = ThinkingEngine(config=config)

        if _is_copilot_mode():
            engine.set_copilot_mode(True)

        return engine
    except Exception as e:
        logger.warning(f"ThinkingEngine åˆå§‹åŒ–å¤±æ•—: {e}")
        return None


# === MCP Tools ===


@mcp.tool()
async def generate_ideas(
    topic: str,
    creativity_level: int = 1,
    count: int = 5,
    constraints: list[str] | None = None,
) -> dict:
    """
    ç”Ÿæˆå‰µæ„é»å­

    Args:
        topic: è¦ç™¼æƒ³çš„ä¸»é¡Œ
        creativity_level: å‰µæ„å±¤ç´š (1=çµ„åˆ, 2=æ¢ç´¢, 3=è®Šé©)
        count: è¦ç”¢ç”Ÿçš„é»å­æ•¸é‡
        constraints: é™åˆ¶æ¢ä»¶åˆ—è¡¨

    Returns:
        åŒ…å«é»å­å’Œé€£çµçš„å­—å…¸
    """
    level = CreativityLevel(creativity_level)
    assoc_range = level.association_range

    ideas = []
    method_used = "brainstorm"

    client = _get_llm_client()
    if client is not None:
        try:
            from cgu.llm import IdeasOutput, SYSTEM_PROMPT_CREATIVITY

            constraints_text = "\n".join(f"- {c}" for c in (constraints or []))
            prompt = f"""ç‚ºä»¥ä¸‹ä¸»é¡Œç”¢ç”Ÿ {count} å€‹å‰µæ„é»å­ï¼š

ä¸»é¡Œï¼š{topic}
å‰µæ„å±¤ç´šï¼š{level.name}ï¼ˆ{level.value}=çµ„åˆå‰µæ„, 2=æ¢ç´¢å‰µæ„, 3=è®Šé©å‰µæ„ï¼‰
{f"é™åˆ¶æ¢ä»¶ï¼š{constraints_text}" if constraints else ""}

è«‹ç”¢ç”Ÿ {count} å€‹å…·é«”ã€å¯åŸ·è¡Œçš„å‰µæ„é»å­ã€‚"""

            result = client.generate_structured(
                prompt=prompt,
                response_model=IdeasOutput,
                system_prompt=SYSTEM_PROMPT_CREATIVITY,
            )
            ideas = [{"id": i+1, "content": idea, "association_score": 0.7 - i*0.05}
                     for i, idea in enumerate(result.ideas[:count])]
            method_used = "llm_brainstorm"
        except Exception as e:
            logger.warning(f"LLM ç”Ÿæˆå¤±æ•—: {e}")

    # Fallback åˆ°æ¨¡æ“¬ï¼ˆæˆ– Copilot æ¨¡å¼æ¡†æ¶ï¼‰
    if not ideas:
        if _is_copilot_mode():
            # Copilot æ¨¡å¼ï¼šè¿”å›æ€è€ƒæ¡†æ¶ï¼Œè®“ Copilot å¡«å……
            ideas = [
                {"id": i + 1, "content": f"[è«‹ Copilot æ€è€ƒ] {topic} çš„ç¬¬ {i + 1} å€‹é»å­", "association_score": 0.5}
                for i in range(count)
            ]
            method_used = "copilot_framework"
        else:
            ideas = [
                {"id": i + 1, "content": f"[æ¨¡æ“¬] {topic} çš„é»å­ {i + 1}", "association_score": 0.5}
                for i in range(count)
            ]

    return {
        "topic": topic,
        "creativity_level": level.name,
        "association_range": f"{assoc_range[0]:.1f} - {assoc_range[1]:.1f}",
        "constraints": constraints or [],
        "ideas": ideas,
        "method_used": method_used,
        "llm_provider": LLM_PROVIDER,
        "copilot_hint": "è«‹æ ¹æ“šä¸Šè¿°æ¡†æ¶ï¼Œç”¨ä½ çš„å‰µæ„å¡«å……å…·é«”é»å­" if _is_copilot_mode() else None,
        "thinking_steps": [
            {"mode": "REACT", "speed": "fast"},
            {"mode": "ASSOCIATE", "speed": "fast"},
            {"mode": "DIVERGE", "speed": "fast"},
        ],
    }


@mcp.tool()
async def spark_collision(
    concept_a: str,
    concept_b: str,
) -> dict:
    """
    æ¦‚å¿µç¢°æ’ - è®“å…©å€‹æ¦‚å¿µç”¢ç”Ÿç«èŠ±

    ä½é—œè¯ä½†æœ‰æ½›åŠ›çš„é€£çµå¾€å¾€èƒ½ç”¢ç”Ÿæœ€æœ‰å‰µæ„çš„é»å­

    Args:
        concept_a: ç¬¬ä¸€å€‹æ¦‚å¿µ
        concept_b: ç¬¬äºŒå€‹æ¦‚å¿µ

    Returns:
        ç¢°æ’ç”¢ç”Ÿçš„ç«èŠ±å’Œç†ç”±
    """
    sparks = []
    rationale = f"å¾ {concept_a} çš„ç‰¹æ€§èˆ‡ {concept_b} çš„ç‰¹æ€§ä¸­æ‰¾åˆ°æ„æƒ³ä¸åˆ°çš„é€£çµ"

    client = _get_llm_client()
    if client is not None:
        try:
            from cgu.llm import SparkOutput, SYSTEM_PROMPT_CREATIVITY, PROMPT_SPARK

            prompt = PROMPT_SPARK.format(
                concept_a=concept_a,
                concept_b=concept_b,
                count=5,
            )
            result = client.generate_structured(
                prompt=prompt,
                response_model=SparkOutput,
                system_prompt=SYSTEM_PROMPT_CREATIVITY,
            )
            sparks = result.sparks
            rationale = result.reasoning
        except Exception as e:
            logger.warning(f"LLM ç¢°æ’å¤±æ•—: {e}")

    # Fallback
    if not sparks:
        sparks = [
            f"[æ¨¡æ“¬] {concept_a} + {concept_b} çš„å‰µæ„çµ„åˆ {i}"
            for i in range(1, 4)
        ]

    return {
        "concept_a": concept_a,
        "concept_b": concept_b,
        "sparks": sparks,
        "rationale": rationale,
        "association_score": 0.3,
    }


@mcp.tool()
async def associative_expansion(
    seed: str,
    direction: str = "similar",
    depth: int = 2,
) -> dict:
    """
    è¯æƒ³æ“´å±• - å¾ç¨®å­æ¦‚å¿µå‘å¤–æ“´å±•

    Args:
        seed: ç¨®å­æ¦‚å¿µ
        direction: æ“´å±•æ–¹å‘ (similar/opposite/random/cross-domain)
        depth: æ“´å±•æ·±åº¦

    Returns:
        æ“´å±•å¾Œçš„è¯æƒ³æ¨¹
    """
    valid_directions = ["similar", "opposite", "random", "cross-domain"]
    if direction not in valid_directions:
        direction = "similar"

    associations = []

    client = _get_llm_client()
    if client is not None:
        try:
            from cgu.llm import AssociationList, SYSTEM_PROMPT_CREATIVITY

            for level in range(1, depth + 1):
                prompt = f"""å¾ã€Œ{seed}ã€é€²è¡Œ {direction} æ–¹å‘çš„è¯æƒ³ï¼Œç¬¬ {level} å±¤æ“´å±•ã€‚
è«‹åˆ—å‡º 3-5 å€‹è¯æƒ³æ¦‚å¿µã€‚

æ–¹å‘èªªæ˜ï¼š
- similar: ç›¸ä¼¼æ¦‚å¿µ
- opposite: ç›¸åæˆ–å°æ¯”æ¦‚å¿µ
- random: éš¨æ©Ÿä½†æœ‰è¶£çš„é€£çµ
- cross-domain: è·¨é ˜åŸŸçš„æ¦‚å¿µ"""

                result = client.generate_structured(
                    prompt=prompt,
                    response_model=AssociationList,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                associations.append({
                    "level": level,
                    "concepts": result.associations[:5],
                })
        except Exception as e:
            logger.warning(f"LLM è¯æƒ³å¤±æ•—: {e}")

    # Fallback
    if not associations:
        associations = [
            {"level": i+1, "concepts": [f"[æ¨¡æ“¬] {seed} çš„ {direction} è¯æƒ³ {j}" for j in range(1, 4)]}
            for i in range(depth)
        ]

    return {
        "seed": seed,
        "direction": direction,
        "depth": depth,
        "associations": associations,
        "thinking_mode": ThinkingMode.ASSOCIATE.value,
        "thinking_speed": ThinkingSpeed.FAST.value,
    }


@mcp.tool()
async def apply_method(
    method: str,
    input_concept: str,
    options: dict | None = None,
) -> dict:
    """
    æ‡‰ç”¨ç‰¹å®šå‰µæ„æ–¹æ³•

    Args:
        method: æ–¹æ³•åç¨± (mind_map/scamper/six_hats/mandala_9grid/...)
        input_concept: è¼¸å…¥æ¦‚å¿µ
        options: æ–¹æ³•ç‰¹å®šé¸é …

    Returns:
        æ–¹æ³•æ‡‰ç”¨çµæœ
    """
    # é©—è­‰æ–¹æ³•
    try:
        creativity_method = CreativityMethod(method)
    except ValueError:
        available = [m.value for m in CreativityMethod]
        return {
            "error": f"Unknown method: {method}",
            "available_methods": available,
        }

    config = METHOD_CONFIGS.get(creativity_method)
    if not config:
        return {"error": f"Method config not found: {method}"}

    result = {
        "method": method,
        "method_description": config.description,
        "category": config.category.value,
        "thinking_speed": config.thinking_speed,
        "agent_strategy": config.agent_strategy,
        "input": input_concept,
        "options": options or {},
    }

    client = _get_llm_client()

    # SCAMPER æ–¹æ³•
    if method == "scamper":
        if client is not None:
            try:
                from cgu.llm import ScamperOutput, SYSTEM_PROMPT_CREATIVITY, PROMPT_SCAMPER
                prompt = PROMPT_SCAMPER.format(topic=input_concept)
                scamper_result = client.generate_structured(
                    prompt=prompt,
                    response_model=ScamperOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "S_substitute": scamper_result.substitute,
                    "C_combine": scamper_result.combine,
                    "A_adapt": scamper_result.adapt,
                    "M_modify": scamper_result.modify,
                    "P_put_to_other_uses": scamper_result.put_to_other_uses,
                    "E_eliminate": scamper_result.eliminate,
                    "R_reverse": scamper_result.reverse,
                    "best_idea": scamper_result.best_idea,
                }
            except Exception as e:
                logger.warning(f"SCAMPER LLM å¤±æ•—: {e}")
                result["output"] = _simulate_scamper(input_concept)
        else:
            result["output"] = _simulate_scamper(input_concept)

    # å…­é ‚æ€è€ƒå¸½
    elif method == "six_hats":
        if client is not None:
            try:
                from cgu.llm import SixHatsOutput, SYSTEM_PROMPT_CREATIVITY
                prompt = f"ä½¿ç”¨å…­é ‚æ€è€ƒå¸½æ–¹æ³•åˆ†æä¸»é¡Œã€Œ{input_concept}ã€ï¼Œå¾ç™½ã€ç´…ã€é»‘ã€é»ƒã€ç¶ ã€è—å…­å€‹è§’åº¦æ€è€ƒã€‚"
                hats_result = client.generate_structured(
                    prompt=prompt,
                    response_model=SixHatsOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "white_facts": hats_result.white,
                    "red_feelings": hats_result.red,
                    "black_risks": hats_result.black,
                    "yellow_benefits": hats_result.yellow,
                    "green_ideas": hats_result.green,
                    "blue_summary": hats_result.blue,
                }
            except Exception as e:
                logger.warning(f"å…­é ‚å¸½ LLM å¤±æ•—: {e}")
                result["output"] = _simulate_six_hats(input_concept)
        else:
            result["output"] = _simulate_six_hats(input_concept)

    # ä¹å®®æ ¼
    elif method == "mandala_9grid":
        if client is not None:
            try:
                from cgu.llm import MandalaOutput, SYSTEM_PROMPT_CREATIVITY, PROMPT_MANDALA
                prompt = PROMPT_MANDALA.format(concept=input_concept)
                mandala_result = client.generate_structured(
                    prompt=prompt,
                    response_model=MandalaOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "center": mandala_result.center,
                    "extensions": mandala_result.extensions,
                }
            except Exception as e:
                logger.warning(f"ä¹å®®æ ¼ LLM å¤±æ•—: {e}")
                result["output"] = _simulate_mandala(input_concept)
        else:
            result["output"] = _simulate_mandala(input_concept)
    # 5W2H æ–¹æ³•
    elif method == "5w2h":
        if client is not None:
            try:
                from cgu.llm import SYSTEM_PROMPT_CREATIVITY
                from pydantic import BaseModel

                class FiveW2HOutput(BaseModel):
                    what: str
                    why: str
                    who: str
                    when: str
                    where: str
                    how: str
                    how_much: str

                prompt = f"""ä½¿ç”¨ 5W2H æ–¹æ³•åˆ†æä»¥ä¸‹ä¸»é¡Œï¼š

ä¸»é¡Œï¼š{input_concept}

è«‹å›ç­”ï¼š
- Whatï¼ˆæ˜¯ä»€éº¼ï¼‰ï¼šé€™æ˜¯ä»€éº¼ï¼Ÿ
- Whyï¼ˆç‚ºä»€éº¼ï¼‰ï¼šç‚ºä»€éº¼è¦åšé€™ä»¶äº‹ï¼Ÿ
- Whoï¼ˆèª°ï¼‰ï¼šèª°ä¾†åšï¼Ÿèª°å—ç›Šï¼Ÿ
- Whenï¼ˆä½•æ™‚ï¼‰ï¼šä»€éº¼æ™‚å€™åšï¼Ÿ
- Whereï¼ˆå“ªè£¡ï¼‰ï¼šåœ¨å“ªè£¡é€²è¡Œï¼Ÿ
- Howï¼ˆå¦‚ä½•ï¼‰ï¼šå¦‚ä½•å¯¦ç¾ï¼Ÿ
- How muchï¼ˆå¤šå°‘ï¼‰ï¼šéœ€è¦å¤šå°‘è³‡æºï¼Ÿ"""

                output = client.generate_structured(
                    prompt=prompt,
                    response_model=FiveW2HOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "what": output.what,
                    "why": output.why,
                    "who": output.who,
                    "when": output.when,
                    "where": output.where,
                    "how": output.how,
                    "how_much": output.how_much,
                }
            except Exception as e:
                logger.warning(f"5W2H LLM å¤±æ•—: {e}")
                result["output"] = _simulate_5w2h(input_concept)
        else:
            result["output"] = _simulate_5w2h(input_concept)

    # é€†å‘æ€è€ƒ
    elif method == "reverse":
        if client is not None:
            try:
                from cgu.llm import ReverseOutput, SYSTEM_PROMPT_CREATIVITY, PROMPT_REVERSE
                prompt = PROMPT_REVERSE.format(problem=input_concept)
                reverse_result = client.generate_structured(
                    prompt=prompt,
                    response_model=ReverseOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "reverse_question": reverse_result.reverse_question,
                    "failure_methods": reverse_result.failure_methods,
                    "solutions": reverse_result.solutions,
                }
            except Exception as e:
                logger.warning(f"Reverse LLM å¤±æ•—: {e}")
                result["output"] = _simulate_reverse(input_concept)
        else:
            result["output"] = _simulate_reverse(input_concept)

    # å¿ƒæ™ºåœ–
    elif method == "mind_map":
        if client is not None:
            try:
                from cgu.llm import MindMapOutput, SYSTEM_PROMPT_CREATIVITY, PROMPT_MIND_MAP
                branches = (options or {}).get("branches", 4)
                sub_branches = (options or {}).get("sub_branches", 3)
                prompt = PROMPT_MIND_MAP.format(topic=input_concept, branches=branches, sub_branches=sub_branches)
                mindmap_result = client.generate_structured(
                    prompt=prompt,
                    response_model=MindMapOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "center": mindmap_result.center,
                    "branches": [
                        {"name": b.name, "sub_branches": b.sub_branches}
                        for b in mindmap_result.branches
                    ],
                }
            except Exception as e:
                logger.warning(f"MindMap LLM å¤±æ•—: {e}")
                result["output"] = _simulate_mind_map(input_concept)
        else:
            result["output"] = _simulate_mind_map(input_concept)

    # è…¦åŠ›æ¿€ç›ª
    elif method == "brainstorm":
        if client is not None:
            try:
                from cgu.llm import IdeasOutput, SYSTEM_PROMPT_CREATIVITY
                count = (options or {}).get("count", 10)
                prompt = f"""å°ä»¥ä¸‹ä¸»é¡Œé€²è¡Œè…¦åŠ›æ¿€ç›ªï¼Œç”¢ç”Ÿ {count} å€‹ä¸å—é™åˆ¶çš„å‰µæ„é»å­ï¼š

ä¸»é¡Œï¼š{input_concept}

è¦å‰‡ï¼š
1. ä¸æ‰¹åˆ¤ä»»ä½•æƒ³æ³•
2. è¶Šç˜‹ç‹‚è¶Šå¥½
3. æ•¸é‡å„ªå…ˆæ–¼è³ªé‡
4. å¯ä»¥çµåˆä»–äººæƒ³æ³•

è«‹åˆ—å‡º {count} å€‹é»å­ï¼š"""
                brainstorm_result = client.generate_structured(
                    prompt=prompt,
                    response_model=IdeasOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {"ideas": brainstorm_result.ideas}
            except Exception as e:
                logger.warning(f"Brainstorm LLM å¤±æ•—: {e}")
                result["output"] = _simulate_brainstorm(input_concept)
        else:
            result["output"] = _simulate_brainstorm(input_concept)

    # éš¨æ©Ÿè¼¸å…¥
    elif method == "random_input":
        import random
        random_words = ["æ˜Ÿç©º", "å’–å•¡", "æ£®æ—", "æ©Ÿå™¨äºº", "éŸ³æ¨‚", "æµ·æ´‹", "å¤¢æƒ³", "æ—…è¡Œ", "é­”æ³•", "æ™‚é–“"]
        random_word = random.choice(random_words)
        if client is not None:
            try:
                from cgu.llm import SparkOutput, SYSTEM_PROMPT_CREATIVITY
                prompt = f"""ä½¿ç”¨éš¨æ©Ÿè©å¼·åˆ¶è¯æƒ³æ³•ï¼š

åŸå§‹ä¸»é¡Œï¼š{input_concept}
éš¨æ©Ÿè©ï¼š{random_word}

è«‹æ€è€ƒï¼š
1. é€™å€‹éš¨æ©Ÿè©è®“ä½ è¯æƒ³åˆ°ä»€éº¼ï¼Ÿ
2. å¦‚ä½•å°‡éš¨æ©Ÿè©èˆ‡åŸå§‹ä¸»é¡Œé€£çµï¼Ÿ
3. ç”¢ç”Ÿ 5 å€‹çµåˆå…©è€…çš„å‰µæ„é»å­"""
                random_result = client.generate_structured(
                    prompt=prompt,
                    response_model=SparkOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                result["output"] = {
                    "random_word": random_word,
                    "sparks": random_result.sparks,
                    "reasoning": random_result.reasoning,
                }
            except Exception as e:
                logger.warning(f"RandomInput LLM å¤±æ•—: {e}")
                result["output"] = _simulate_random_input(input_concept, random_word)
        else:
            result["output"] = _simulate_random_input(input_concept, random_word)
    else:
        result["output"] = f"[æ¨¡æ“¬] {method} æ–¹æ³•æ‡‰ç”¨æ–¼ {input_concept}"

    return result


def _simulate_scamper(concept: str) -> dict:
    """æ¨¡æ“¬ SCAMPER è¼¸å‡º"""
    return {
        "S_substitute": f"[æ¨¡æ“¬] æ›¿ä»£ {concept}",
        "C_combine": f"[æ¨¡æ“¬] çµåˆ {concept}",
        "A_adapt": f"[æ¨¡æ“¬] èª¿é© {concept}",
        "M_modify": f"[æ¨¡æ“¬] ä¿®æ”¹ {concept}",
        "P_put_to_other_uses": f"[æ¨¡æ“¬] ä»–ç”¨ {concept}",
        "E_eliminate": f"[æ¨¡æ“¬] æ¶ˆé™¤ {concept}",
        "R_reverse": f"[æ¨¡æ“¬] é‡æ’ {concept}",
    }


def _simulate_six_hats(concept: str) -> dict:
    """æ¨¡æ“¬å…­é ‚å¸½è¼¸å‡º"""
    return {
        "white_facts": f"[æ¨¡æ“¬] é—œæ–¼ {concept} çš„äº‹å¯¦",
        "red_feelings": f"[æ¨¡æ“¬] å° {concept} çš„æ„Ÿè¦º",
        "black_risks": f"[æ¨¡æ“¬] {concept} çš„é¢¨éšª",
        "yellow_benefits": f"[æ¨¡æ“¬] {concept} çš„å¥½è™•",
        "green_ideas": f"[æ¨¡æ“¬] {concept} çš„æ–°é»å­",
        "blue_summary": f"[æ¨¡æ“¬] {concept} çš„ç¸½çµ",
    }


def _simulate_mandala(concept: str) -> dict:
    """æ¨¡æ“¬ä¹å®®æ ¼è¼¸å‡º"""
    return {
        "center": concept,
        "extensions": [f"[æ¨¡æ“¬] {concept} å»¶ä¼¸ {i}" for i in range(1, 9)],
    }


def _simulate_5w2h(concept: str) -> dict:
    """æ¨¡æ“¬ 5W2H è¼¸å‡º"""
    return {
        "what": f"[æ¨¡æ“¬] {concept} æ˜¯ä»€éº¼",
        "why": f"[æ¨¡æ“¬] ç‚ºä»€éº¼è¦ {concept}",
        "who": f"[æ¨¡æ“¬] èª°åƒèˆ‡ {concept}",
        "when": f"[æ¨¡æ“¬] ä½•æ™‚é€²è¡Œ {concept}",
        "where": f"[æ¨¡æ“¬] åœ¨å“ªè£¡é€²è¡Œ {concept}",
        "how": f"[æ¨¡æ“¬] å¦‚ä½•å¯¦ç¾ {concept}",
        "how_much": f"[æ¨¡æ“¬] {concept} éœ€è¦å¤šå°‘è³‡æº",
    }


def _simulate_reverse(concept: str) -> dict:
    """æ¨¡æ“¬é€†å‘æ€è€ƒè¼¸å‡º"""
    return {
        "reverse_question": f"[æ¨¡æ“¬] å¦‚ä½•è®“ {concept} å¤±æ•—ï¼Ÿ",
        "failure_methods": [f"[æ¨¡æ“¬] å¤±æ•—æ–¹æ³• {i}" for i in range(1, 6)],
        "solutions": [f"[æ¨¡æ“¬] åè½‰è§£æ³• {i}" for i in range(1, 6)],
    }


def _simulate_mind_map(concept: str) -> dict:
    """æ¨¡æ“¬å¿ƒæ™ºåœ–è¼¸å‡º"""
    return {
        "center": concept,
        "branches": [
            {"name": f"åˆ†æ”¯ {i}", "sub_branches": [f"å­åˆ†æ”¯ {i}.{j}" for j in range(1, 4)]}
            for i in range(1, 5)
        ],
    }


def _simulate_brainstorm(concept: str) -> dict:
    """æ¨¡æ“¬è…¦åŠ›æ¿€ç›ªè¼¸å‡º"""
    return {
        "ideas": [f"[æ¨¡æ“¬] {concept} çš„ç˜‹ç‹‚é»å­ {i}" for i in range(1, 11)],
    }


def _simulate_random_input(concept: str, random_word: str) -> dict:
    """æ¨¡æ“¬éš¨æ©Ÿè¼¸å…¥è¼¸å‡º"""
    return {
        "random_word": random_word,
        "sparks": [f"[æ¨¡æ“¬] {concept} + {random_word} çš„çµ„åˆ {i}" for i in range(1, 6)],
        "reasoning": f"[æ¨¡æ“¬] å°‡ {random_word} çš„ç‰¹æ€§èˆ‡ {concept} çµåˆ",
    }


@mcp.tool()
async def select_method(
    creativity_level: int = 1,
    prefer_fast: bool = True,
    is_stuck: bool = False,
    purpose: str | None = None,
) -> dict:
    """
    æ ¹æ“šæƒ…æ³é¸æ“‡åˆé©çš„å‰µæ„æ–¹æ³•

    Args:
        creativity_level: å‰µæ„å±¤ç´š (1/2/3)
        prefer_fast: æ˜¯å¦åå¥½å¿«é€Ÿæ–¹æ³•
        is_stuck: æ˜¯å¦å¡é—œä¸­
        purpose: ç›®çš„ (å»£æ³›æ¢ç´¢/çµæ§‹åŒ–åˆ†æ/å¼·åˆ¶å‰µæ–°/ç³»çµ±æ€§çµ„åˆ/å¤šå…ƒè§€é»/å•é¡Œåè½‰/å®Œæ•´æµç¨‹)

    Returns:
        æ¨è–¦çš„æ–¹æ³•å’Œé…ç½®
    """
    level = CreativityLevel(creativity_level)
    method = select_method_for_task(
        creativity_level=level,
        prefer_fast=prefer_fast,
        is_stuck=is_stuck,
        purpose=purpose,
    )

    config = METHOD_CONFIGS.get(method)

    return {
        "recommended_method": method.value,
        "description": config.description if config else "",
        "category": config.category.value if config else "",
        "thinking_speed": config.thinking_speed if config else "fast",
        "agent_strategy": config.agent_strategy if config else "",
        "selection_reason": {
            "creativity_level": level.name,
            "prefer_fast": prefer_fast,
            "is_stuck": is_stuck,
            "purpose": purpose,
        },
    }


# === æ–°å¢ï¼šæ·±åº¦æ€è€ƒå·¥å…· ===


@mcp.tool()
async def deep_think(
    topic: str,
    depth: str = "medium",
    mode: str | None = None,
) -> dict:
    """
    çµ±ä¸€æ€è€ƒä»‹é¢ - æ™ºèƒ½é¸æ“‡æ€è€ƒæ·±åº¦

    Args:
        topic: æ€è€ƒä¸»é¡Œ
        depth: æ€è€ƒæ·±åº¦ - "shallow"ï¼ˆå¿«é€Ÿï¼‰/ "medium"ï¼ˆé©ä¸­ï¼‰/ "deep"ï¼ˆæ·±å…¥ï¼‰
        mode: å¼·åˆ¶æ¨¡å¼ - "simple"ï¼ˆå–®æ¬¡ï¼‰/ "deep"ï¼ˆå¤šAgentï¼‰/ "spark"ï¼ˆç¢°æ’ï¼‰/ Noneï¼ˆè‡ªå‹•ï¼‰

    Returns:
        åŒ…å«é»å­ã€ç«èŠ±ã€æ¨ç†éç¨‹çš„å®Œæ•´çµæœ
    """
    engine = _get_thinking_engine()

    if engine is None:
        # Fallback åˆ°å‚³çµ±æ¨¡å¼
        return await generate_ideas(topic=topic, count=5)

    try:
        from cgu.thinking import ThinkingMode as TMode, ThinkingDepth

        # è§£ææ·±åº¦
        depth_map = {
            "shallow": ThinkingDepth.SHALLOW,
            "medium": ThinkingDepth.MEDIUM,
            "deep": ThinkingDepth.DEEP,
        }

        # è§£ææ¨¡å¼
        mode_map = {
            "simple": TMode.SIMPLE,
            "deep": TMode.DEEP,
            "spark": TMode.SPARK,
            "hybrid": TMode.HYBRID,
        }

        result = await engine.think(
            topic=topic,
            mode=mode_map.get(mode) if mode else None,
            depth=depth_map.get(depth, ThinkingDepth.MEDIUM),
        )

        return result.to_dict()

    except Exception as e:
        logger.error(f"æ·±åº¦æ€è€ƒå¤±æ•—: {e}")
        return {
            "error": str(e),
            "fallback": await generate_ideas(topic=topic, count=5),
        }


@mcp.tool()
async def multi_agent_brainstorm(
    topic: str,
    agents: int = 3,
    thinking_steps: int = 3,
    collision_count: int = 5,
) -> dict:
    """
    å¤š Agent ä¸¦ç™¼è…¦åŠ›æ¿€ç›ª

    å¤šå€‹ç¨ç«‹ Agentï¼ˆExplorerã€Criticã€Wildcardï¼‰ä¸¦ç™¼æ€è€ƒåŒä¸€ä¸»é¡Œï¼Œ
    å„è‡ªç¶­è­·ç¨ç«‹ Context é¿å…æ±¡æŸ“ï¼Œæœ€å¾Œç¢°æ’ç”¢ç”Ÿç«èŠ±ã€‚

    Args:
        topic: æ€è€ƒä¸»é¡Œ
        agents: Agent æ•¸é‡ï¼ˆ1-5ï¼‰
        thinking_steps: æ¯å€‹ Agent çš„æ€è€ƒæ­¥æ•¸
        collision_count: æ¦‚å¿µç¢°æ’æ¬¡æ•¸

    Returns:
        åŒ…å«å„ Agent è²¢ç»ã€ç«èŠ±ã€æœ€ä½³æƒ³æ³•çš„çµæœ
    """
    engine = _get_thinking_engine()

    if engine is None:
        return {
            "error": "ThinkingEngine æœªåˆå§‹åŒ–",
            "hint": "è«‹ç¢ºèª cgu.thinking æ¨¡çµ„å¯ç”¨",
        }

    try:
        from cgu.thinking import ThinkingMode

        result = await engine.think(
            topic=topic,
            mode=ThinkingMode.DEEP,
            agent_count=min(max(agents, 1), 5),  # é™åˆ¶ 1-5
            thinking_steps=thinking_steps,
            collision_count=collision_count,
        )

        return {
            "topic": topic,
            "mode": "multi_agent",
            "agent_contributions": result.agent_contributions,
            "all_ideas": result.ideas,
            "sparks": result.sparks,
            "best_ideas": result.best_ideas,
            "best_spark": result.best_spark,
            "stats": {
                "total_time_ms": result.total_time_ms,
                "idea_count": len(result.ideas),
                "spark_count": len(result.sparks),
            },
        }

    except Exception as e:
        logger.error(f"Multi-Agent è…¦åŠ›æ¿€ç›ªå¤±æ•—: {e}")
        return {"error": str(e)}


@mcp.tool()
async def spark_collision_deep(
    concept_a: str,
    concept_b: str,
    collision_count: int = 5,
) -> dict:
    """
    æ·±åº¦æ¦‚å¿µç¢°æ’ - ä½¿ç”¨ Multi-Agent ç”¢ç”Ÿæ„å¤–ç«èŠ±

    ä¸åŒæ–¼ç°¡å–®çš„ spark_collisionï¼Œæ­¤å·¥å…·ä½¿ç”¨å¤šå€‹ Agent
    å¾ä¸åŒè§’åº¦æ¢ç´¢å…©å€‹æ¦‚å¿µçš„é€£çµå¯èƒ½æ€§ã€‚

    Args:
        concept_a: ç¬¬ä¸€å€‹æ¦‚å¿µ
        concept_b: ç¬¬äºŒå€‹æ¦‚å¿µ
        collision_count: ç¢°æ’æ¬¡æ•¸

    Returns:
        åŒ…å«å¤šå±¤æ¬¡ç«èŠ±å’Œé©šå–œåº¦è©•åˆ†çš„çµæœ
    """
    engine = _get_thinking_engine()

    if engine is None:
        return await spark_collision(concept_a, concept_b)

    try:
        from cgu.thinking import ThinkingMode

        topic = f"{concept_a} Ã— {concept_b}"

        result = await engine.think(
            topic=topic,
            mode=ThinkingMode.SPARK,
            collision_count=collision_count,
        )

        return {
            "concept_a": concept_a,
            "concept_b": concept_b,
            "collision_count": collision_count,
            "sparks": result.sparks,
            "best_spark": result.best_spark,
            "ideas": result.ideas,
            "reasoning": result.reasoning_chains,
        }

    except Exception as e:
        logger.error(f"æ·±åº¦ç¢°æ’å¤±æ•—: {e}")
        return await spark_collision(concept_a, concept_b)


@mcp.tool()
async def list_methods() -> dict:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å‰µæ„æ–¹æ³•

    Returns:
        æ‰€æœ‰æ–¹æ³•çš„æ¸…å–®å’Œèªªæ˜
    """
    methods_by_category: dict[str, list[dict]] = {}

    for method, config in METHOD_CONFIGS.items():
        category = config.category.value
        if category not in methods_by_category:
            methods_by_category[category] = []

        methods_by_category[category].append({
            "name": method.value,
            "description": config.description,
            "thinking_speed": config.thinking_speed,
            "suitable_levels": config.suitable_levels,
        })

    return {
        "total_methods": len(METHOD_CONFIGS),
        "categories": list(methods_by_category.keys()),
        "methods_by_category": methods_by_category,
    }


# === Spark-Soup: Context Stuffing for Creativity ===


@mcp.tool()
async def spark_soup_generate(
    topic: str,
    fragment_count: int = 20,
    topic_repetition: int = 5,
    auto_search: bool = False,
    custom_fragments: list[str] | None = None,
    trigger_categories: list[str] | None = None,
    randomness: float = 0.5,
) -> dict:
    """
    çµ„è£ã€Œå‰µæ„æ¹¯ã€- ç”¨ç¢ç‰‡åŒ–è³‡è¨Šå¡«å…… contextï¼Œæ¿€ç™¼æ„å¤–é€£çµ

    æ¨¡æ“¬äººé¡æ¥æ”¶æ–°è/æ›¸ç±/é«”é©—å¾Œç”¢ç”Ÿå‰µæ„çš„éç¨‹ã€‚

    Args:
        topic: ä¸»é¡Œï¼ˆæœƒåœ¨ soup ä¸­é‡è¤‡å¤šæ¬¡é¿å…éºå¿˜ï¼‰
        fragment_count: ç¢ç‰‡æ•¸é‡ï¼ˆé è¨­ 20ï¼‰
        topic_repetition: ä¸»é¡Œé‡è¤‡æ¬¡æ•¸ï¼ˆé è¨­ 5ï¼Œé¿å…è¢« context å£“ç¸®éºå¿˜ï¼‰
        auto_search: æ˜¯å¦è‡ªå‹•æœå°‹å¤–éƒ¨è³‡è¨Šï¼ˆéœ€è¦ç¶²è·¯ï¼‰
        custom_fragments: ä½¿ç”¨è€…è‡ªè¨‚ç¢ç‰‡åˆ—è¡¨
        trigger_categories: è§¸ç™¼è©é¡åˆ¥
            å¯é¸: ["combination", "inversion", "scale", "time", "perspective", "emotion"]
        randomness: éš¨æ©Ÿæ€§ 0-1ï¼ˆè¶Šé«˜ç¢ç‰‡è¶Šéš¨æ©Ÿï¼‰

    Returns:
        åŒ…å«å‰µæ„æ¹¯ã€ç¢ç‰‡è³‡è¨Šã€å¤šæ¨£æ€§è©•åˆ†çš„çµæœ
    """
    try:
        from cgu.soup import spark_soup

        result = await spark_soup(
            topic=topic,
            fragment_count=fragment_count,
            topic_repetition=topic_repetition,
            auto_search=auto_search,
            custom_fragments=custom_fragments,
            trigger_categories=trigger_categories,
            randomness=randomness,
        )

        return {
            "success": True,
            "soup": result.soup,
            "topic": result.topic,
            "fragments_count": len(result.fragments_used),
            "diversity_score": result.diversity_score,
            "trigger_words_used": result.trigger_words_used,
            "sources": list(set(f.source.value for f in result.fragments_used)),
            "usage_hint": "è«‹å°‡ soup å…§å®¹å‚³çµ¦ LLMï¼Œè®“å®ƒå¾ç¢ç‰‡ä¸­å°‹æ‰¾æ„å¤–é€£çµä¾†ç”¢ç”Ÿå‰µæ„æƒ³æ³•",
        }

    except Exception as e:
        logger.error(f"Spark Soup å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "hint": "è«‹ç¢ºèª cgu.soup æ¨¡çµ„å¯ç”¨",
        }


@mcp.tool()
async def spark_soup_quick(
    topic: str,
    creativity_boost: float = 0.7,
) -> dict:
    """
    å¿«é€Ÿå‰µæ„æ¹¯ - ä¸€éµç”¢ç”Ÿå‰µæ„æ¹¯ä¸¦ç›´æ¥ç”Ÿæˆæƒ³æ³•

    çµåˆ spark_soup + generate_ideasï¼Œé©åˆå¿«é€Ÿç™¼æƒ³ã€‚

    Args:
        topic: ä¸»é¡Œ
        creativity_boost: å‰µæ„å¢å¼·ç¨‹åº¦ 0-1ï¼ˆå½±éŸ¿éš¨æ©Ÿæ€§å’Œç¢ç‰‡å¤šæ¨£æ€§ï¼‰

    Returns:
        å‰µæ„æ¹¯å’ŒåŸºæ–¼æ¹¯åº•ç”¢ç”Ÿçš„æƒ³æ³•
    """
    try:
        from cgu.soup import spark_soup

        # ç”Ÿæˆå‰µæ„æ¹¯
        soup_result = await spark_soup(
            topic=topic,
            fragment_count=15,
            topic_repetition=3,
            auto_search=False,
            randomness=creativity_boost,
            trigger_categories=["combination", "perspective"],
        )

        # ä½¿ç”¨ LLM åŸºæ–¼å‰µæ„æ¹¯ç”Ÿæˆæƒ³æ³•
        client = _get_llm_client()
        ideas = []

        if client is not None:
            try:
                from cgu.llm import IdeasOutput, SYSTEM_PROMPT_CREATIVITY

                prompt = f"""è«‹åŸºæ–¼ä»¥ä¸‹ã€Œå‰µæ„æ¹¯ã€ç”¢ç”Ÿ 5 å€‹å‰µæ„æƒ³æ³•ã€‚

{soup_result.soup}

è«‹å¾ç¢ç‰‡ä¸­å°‹æ‰¾æ„å¤–çš„é€£çµï¼Œç”¢ç”Ÿæ–°ç©çš„æƒ³æ³•ã€‚"""

                result = client.generate_structured(
                    prompt=prompt,
                    response_model=IdeasOutput,
                    system_prompt=SYSTEM_PROMPT_CREATIVITY,
                )
                ideas = [
                    {"id": i+1, "content": idea, "source": "spark_soup"}
                    for i, idea in enumerate(result.ideas[:5])
                ]
            except Exception as e:
                logger.warning(f"LLM ç”Ÿæˆå¤±æ•—: {e}")

        # Fallback
        if not ideas:
            ideas = [
                {"id": i+1, "content": f"[è«‹åŸºæ–¼å‰µæ„æ¹¯æ€è€ƒ] {topic} çš„æƒ³æ³• {i+1}", "source": "framework"}
                for i in range(5)
            ]

        return {
            "success": True,
            "topic": topic,
            "ideas": ideas,
            "soup_preview": soup_result.soup[:500] + "..." if len(soup_result.soup) > 500 else soup_result.soup,
            "diversity_score": soup_result.diversity_score,
            "fragments_count": len(soup_result.fragments_used),
        }

    except Exception as e:
        logger.error(f"Quick Spark Soup å¤±æ•—: {e}")
        return await generate_ideas(topic=topic, count=5)


@mcp.tool()
async def collect_creativity_fragments(
    topic: str,
    count: int = 10,
    include_quotes: bool = True,
    include_random_concepts: bool = True,
    include_search: bool = False,
    randomness: float = 0.5,
) -> dict:
    """
    æ”¶é›†å‰µæ„ç¢ç‰‡ - å¾å¤šå€‹ä¾†æºæ”¶é›†ç¢ç‰‡åŒ–è³‡è¨Š

    å¯ç”¨æ–¼è‡ªè¨‚å‰µæ„æ¹¯çš„çµ„è£ï¼Œæˆ–å–®ç¨ä½¿ç”¨ç¢ç‰‡é€²è¡Œè¯æƒ³ã€‚

    Args:
        topic: ç›¸é—œä¸»é¡Œï¼ˆç”¨æ–¼å¼•å°æœå°‹ï¼‰
        count: æ”¶é›†æ•¸é‡
        include_quotes: æ˜¯å¦åŒ…å«åè¨€é‡‘å¥
        include_random_concepts: æ˜¯å¦åŒ…å«éš¨æ©Ÿæ¦‚å¿µ
        include_search: æ˜¯å¦é€²è¡Œç¶²è·¯æœå°‹ï¼ˆéœ€è¦ç¶²è·¯ï¼‰
        randomness: éš¨æ©Ÿæ€§ 0-1

    Returns:
        æ”¶é›†åˆ°çš„ç¢ç‰‡åˆ—è¡¨
    """
    try:
        from cgu.soup import collect_fragments

        sources = []
        if include_quotes:
            sources.append("quotes")
        if include_random_concepts:
            sources.append("random")
        if include_search:
            sources.append("duckduckgo")

        if not sources:
            sources = ["quotes", "random"]

        fragments = await collect_fragments(
            topic=topic,
            sources=sources,
            count_per_source=max(3, count // len(sources)),
            randomness=randomness,
        )

        return {
            "success": True,
            "topic": topic,
            "fragments": [
                {
                    "content": f.content,
                    "source": f.source.value,
                    "relevance": f.relevance,
                }
                for f in fragments[:count]
            ],
            "total": len(fragments),
        }

    except Exception as e:
        logger.error(f"æ”¶é›†ç¢ç‰‡å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
        }


@mcp.tool()
async def get_trigger_words(
    categories: list[str] | None = None,
    count: int = 10,
) -> dict:
    """
    å–å¾—å‰µæ„è§¸ç™¼è© - ç”¨æ–¼æ¿€ç™¼å‰µæ„çš„æå•

    Args:
        categories: é¡åˆ¥åˆ—è¡¨
            å¯é¸: ["combination", "inversion", "scale", "time", "perspective", "emotion"]
        count: æ•¸é‡

    Returns:
        è§¸ç™¼è©åˆ—è¡¨
    """
    try:
        from cgu.soup import TRIGGER_WORDS
        import random

        requested_cats = categories or list(TRIGGER_WORDS.keys())

        all_triggers = []
        triggers_by_category = {}

        for cat in requested_cats:
            if cat in TRIGGER_WORDS:
                triggers = TRIGGER_WORDS[cat]
                triggers_by_category[cat] = triggers
                all_triggers.extend(triggers)

        # éš¨æ©Ÿé¸æ“‡
        selected = random.sample(all_triggers, min(count, len(all_triggers)))

        return {
            "success": True,
            "selected": selected,
            "by_category": triggers_by_category,
            "available_categories": list(TRIGGER_WORDS.keys()),
        }

    except Exception as e:
        logger.error(f"å–å¾—è§¸ç™¼è©å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
        }


# === MCP Resources ===


@mcp.resource("cgu://creativity-levels")
async def get_creativity_levels() -> str:
    """å–å¾—å‰µæ„å±¤ç´šèªªæ˜"""
    return """
# CGU Creativity Levels

## Level 1: Combinational (çµ„åˆå‰µæ„)
- Association Range: 0.7 - 1.0
- Description: å·²çŸ¥å…ƒç´ çš„æ–°çµ„åˆ
- Example: å°‡ç¾æœ‰åŠŸèƒ½é‡æ–°çµ„åˆ

## Level 2: Exploratory (æ¢ç´¢å‰µæ„)
- Association Range: 0.3 - 0.7
- Description: åœ¨æ—¢æœ‰è¦å‰‡å…§æ¢ç´¢é‚Šç•Œ
- Example: å»¶ä¼¸ç¾æœ‰æ¦‚å¿µåˆ°æ–°é ˜åŸŸ

## Level 3: Transformational (è®Šé©å‰µæ„)
- Association Range: 0.0 - 0.3
- Description: æ‰“ç ´è¦å‰‡ï¼Œå‰µé€ æ–°ç¯„å¼
- Example: é¡›è¦†æ€§çš„å…¨æ–°æ¦‚å¿µ
"""


@mcp.resource("cgu://thinking-modes")
async def get_thinking_modes() -> str:
    """å–å¾—æ€è€ƒæ¨¡å¼èªªæ˜"""
    return """
# CGU Thinking Modes (Fast/Slow)

## System 1 - Fast Thinking âš¡
- REACT: åŸºæœ¬åæ‡‰ï¼Œè¼¸å…¥ â†’ è¼¸å‡º
- ASSOCIATE: å¿«é€Ÿè¯æƒ³ï¼Œæ¦‚å¿µ â†’ ç›¸é—œæ¦‚å¿µ
- PATTERN_MATCH: æ¨¡å¼åŒ¹é…ï¼Œè­˜åˆ¥å·²çŸ¥æ¨¡å¼

## System 2 - Slow Thinking ğŸ¢
- ANALYZE: åˆ†æï¼Œæ‹†è§£å•é¡Œçµæ§‹
- SYNTHESIZE: ç¶œåˆï¼Œçµ„åˆå¤šå€‹æ¦‚å¿µ
- EVALUATE: è©•ä¼°ï¼Œåˆ¤æ–·å“è³ªèˆ‡å¯è¡Œæ€§

## Creative Thinking ğŸ¨
- DIVERGE: ç™¼æ•£ï¼Œç”¢ç”Ÿå¤šç¨®å¯èƒ½
- CONVERGE: æ”¶æ–‚ï¼Œé¸æ“‡æœ€ä½³æ–¹æ¡ˆ
- TRANSFORM: è®Šé©ï¼Œæ‰“ç ´è¦å‰‡å‰µæ–°

## Fast/Slow Patterns
- sprint: 5 fast + 1 slow (å¿«é€Ÿå˜—è©¦ + è©•ä¼°)
- explore: 3 fast + 1 slow (å¿«é€Ÿè¯æƒ³ + åˆ†æ)
- refine: 2 fast + 2 slow (ç”Ÿæˆ + ç²¾ç…‰)
- deep: 1 fast + 3 slow (ç›´è¦º + æ·±æ€)
"""


# === Entry Point ===


def main():
    """å•Ÿå‹• MCP Server"""
    mcp.run()


if __name__ == "__main__":
    main()
