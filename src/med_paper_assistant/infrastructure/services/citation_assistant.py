"""
Citation Assistant - æ™ºæ…§å¼•ç”¨åŠ©æ‰‹

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åˆ†æä¸€æ®µæ–‡å­—ï¼Œç†è§£éœ€è¦ä»€éº¼é¡å‹çš„å¼•ç”¨æ”¯æŒ
2. å¾å°ˆæ¡ˆå·²å­˜æ–‡ç»ä¸­æ‰¾å‡ºæœ€ç›¸é—œçš„
3. å»ºè­°éœ€è¦æœå°‹çš„æ–°æ–‡ç»ä¸»é¡Œ
4. æ”¯æ´æ‰¹é‡å¼•ç”¨å»ºè­°ï¼ˆæ•´ç¯‡ draft æƒæï¼‰

èˆ‡ Foam æ•´åˆï¼š
- è¼¸å‡ºä½¿ç”¨ [[citation_key]] æ ¼å¼
- å¯ç›´æ¥è²¼å…¥ markdown
- æ”¯æ´ hover preview

Architecture:
    CitationAssistant (Application Service)
    â”œâ”€â”€ _analyze_text_claims() - åˆ†ææ–‡å­—ä¸­çš„ claims
    â”œâ”€â”€ _search_local_references() - æœ¬åœ°æœå°‹
    â”œâ”€â”€ _generate_pubmed_queries() - ç”Ÿæˆ PubMed æœå°‹å»ºè­°
    â””â”€â”€ suggest_citations() - ä¸»å…¥å£
"""

import re
from dataclasses import dataclass, field
from enum import Enum
from typing import TYPE_CHECKING, Any, Optional

if TYPE_CHECKING:
    from med_paper_assistant.infrastructure.persistence.reference_manager import ReferenceManager


class ClaimType(Enum):
    """æ–‡å­—è²ç¨±çš„é¡å‹ï¼Œæ±ºå®šéœ€è¦ä»€éº¼é¡å‹çš„å¼•ç”¨"""

    STATISTICAL = "statistical"  # çµ±è¨ˆæ•¸æ“š (e.g., "ç™¼ç”Ÿç‡ç‚º 15%")
    COMPARISON = "comparison"  # æ¯”è¼ƒè²ç¨± (e.g., "A æ¯” B æ›´å¥½")
    MECHANISM = "mechanism"  # æ©Ÿåˆ¶èªªæ˜ (e.g., "é€é...ä½œç”¨")
    HISTORICAL = "historical"  # æ­·å²/èƒŒæ™¯ (e.g., "è‡ª1990å¹´ä»¥ä¾†...")
    GUIDELINE = "guideline"  # æŒ‡å¼•å»ºè­° (e.g., "æŒ‡å¼•å»ºè­°...")
    CONSENSUS = "consensus"  # å…±è­˜ (e.g., "æ™®éèªç‚º...")
    DEFINITION = "definition"  # å®šç¾© (e.g., "...å®šç¾©ç‚º...")
    GENERAL = "general"  # ä¸€èˆ¬æ€§é™³è¿°


@dataclass
class TextClaim:
    """å¾æ–‡å­—ä¸­æå–çš„è²ç¨±"""

    text: str  # åŸæ–‡
    claim_type: ClaimType
    key_terms: list[str]  # é—œéµè©
    needs_citation: bool  # æ˜¯å¦éœ€è¦å¼•ç”¨
    reason: str  # åŸå› èªªæ˜
    suggested_search: str = ""  # å»ºè­°çš„ PubMed æœå°‹è©


@dataclass
class CitationSuggestion:
    """å¼•ç”¨å»ºè­°"""

    pmid: str
    citation_key: str
    title: str
    relevance_score: float  # 0-1
    relevance_reason: str
    matching_terms: list[str]
    source: str  # "local" or "pubmed_suggested"


@dataclass
class CitationAnalysisResult:
    """å®Œæ•´çš„å¼•ç”¨åˆ†æçµæœ"""

    original_text: str
    claims: list[TextClaim]
    local_suggestions: list[CitationSuggestion]
    pubmed_search_queries: list[str]
    has_existing_citations: bool
    existing_citations: list[str]
    summary: str = ""

    def to_markdown(self) -> str:
        """è¼¸å‡ºç‚º Markdown æ ¼å¼å ±å‘Š"""
        output = "## ğŸ” Citation Analysis Report\n\n"

        # 1. ç¾æœ‰å¼•ç”¨
        if self.existing_citations:
            output += "### âœ… Existing Citations\n"
            for cit in self.existing_citations:
                output += f"- `[[{cit}]]`\n"
            output += "\n"

        # 2. åˆ†æå‡ºçš„è²ç¨±
        needs_citation_claims = [c for c in self.claims if c.needs_citation]
        if needs_citation_claims:
            output += "### ğŸ“ Statements Requiring Citations\n\n"
            output += "| Statement | Type | Reason |\n"
            output += "|-----------|------|--------|\n"
            for claim in needs_citation_claims:
                text_preview = claim.text[:50] + "..." if len(claim.text) > 50 else claim.text
                output += f"| {text_preview} | {claim.claim_type.value} | {claim.reason} |\n"
            output += "\n"

        # 3. æœ¬åœ°æ–‡ç»å»ºè­°
        if self.local_suggestions:
            output += "### ğŸ“š Suggested from Local Library\n\n"
            for sug in sorted(self.local_suggestions, key=lambda x: -x.relevance_score)[:5]:
                score_bar = "â–ˆ" * int(sug.relevance_score * 5) + "â–‘" * (5 - int(sug.relevance_score * 5))
                output += f"**[[{sug.citation_key}]]** [{score_bar}]\n"
                output += f"  - {sug.title[:60]}...\n"
                output += f"  - ç›¸é—œæ€§: {sug.relevance_reason}\n"
                output += f"  - åŒ¹é…è©: {', '.join(sug.matching_terms)}\n\n"
        else:
            output += "### ğŸ“š Local Library\n"
            output += "*No relevant references found in local library.*\n\n"

        # 4. PubMed æœå°‹å»ºè­°
        if self.pubmed_search_queries:
            output += "### ğŸ” Suggested PubMed Searches\n\n"
            output += "Use `pubmed-search` MCP to find new references:\n\n"
            for i, query in enumerate(self.pubmed_search_queries[:3], 1):
                output += f"{i}. `search_literature(\"{query}\")`\n"
            output += "\n"

        # 5. ç¸½çµ
        if self.summary:
            output += f"### ğŸ’¡ Summary\n\n{self.summary}\n"

        return output


class CitationAssistant:
    """æ™ºæ…§å¼•ç”¨åŠ©æ‰‹"""

    def __init__(self, reference_manager: "ReferenceManager"):
        self.ref_manager = reference_manager

    def analyze_text(
        self,
        text: str,
        context: str = "",
        search_local: bool = True,
        generate_queries: bool = True,
    ) -> CitationAnalysisResult:
        """
        åˆ†æä¸€æ®µæ–‡å­—ï¼Œæä¾›å¼•ç”¨å»ºè­°ã€‚

        Args:
            text: è¦åˆ†æçš„æ–‡å­—
            context: é¡å¤–ä¸Šä¸‹æ–‡ï¼ˆå¦‚ç« ç¯€æ¨™é¡Œï¼‰
            search_local: æ˜¯å¦æœå°‹æœ¬åœ°æ–‡ç»åº«
            generate_queries: æ˜¯å¦ç”Ÿæˆ PubMed æœå°‹å»ºè­°

        Returns:
            CitationAnalysisResult åŒ…å«å®Œæ•´åˆ†æ
        """
        # 1. æª¢æŸ¥ç¾æœ‰å¼•ç”¨
        existing = self._extract_existing_citations(text)

        # 2. åˆ†ææ–‡å­—ä¸­çš„è²ç¨±
        claims = self._analyze_text_claims(text)

        # 3. æœ¬åœ°æœå°‹
        local_suggestions = []
        if search_local:
            local_suggestions = self._search_local_for_claims(claims)

        # 4. ç”Ÿæˆ PubMed æœå°‹å»ºè­°
        pubmed_queries = []
        if generate_queries:
            pubmed_queries = self._generate_pubmed_queries(claims, local_suggestions)

        # 5. ç”Ÿæˆç¸½çµ
        summary = self._generate_summary(claims, local_suggestions, pubmed_queries)

        return CitationAnalysisResult(
            original_text=text,
            claims=claims,
            local_suggestions=local_suggestions,
            pubmed_search_queries=pubmed_queries,
            has_existing_citations=len(existing) > 0,
            existing_citations=existing,
            summary=summary,
        )

    def suggest_for_selection(
        self,
        selected_text: str,
        draft_content: str = "",
        section: str = "",
    ) -> str:
        """
        ç‚ºç”¨æˆ¶é¸å–çš„æ–‡å­—æä¾›å¼•ç”¨å»ºè­°ã€‚

        é€™æ˜¯ä¸»è¦çš„ç”¨æˆ¶ä»‹é¢æ–¹æ³•ã€‚

        Args:
            selected_text: ç”¨æˆ¶é¸å–çš„æ–‡å­—
            draft_content: å®Œæ•´çš„è‰ç¨¿å…§å®¹ï¼ˆç”¨æ–¼ä¸Šä¸‹æ–‡ï¼‰
            section: æ‰€åœ¨ç« ç¯€ï¼ˆIntroduction/Methods/Results/Discussionï¼‰

        Returns:
            Markdown æ ¼å¼çš„å»ºè­°å ±å‘Š
        """
        context = f"Section: {section}" if section else ""
        result = self.analyze_text(selected_text, context=context)
        return result.to_markdown()

    def scan_draft_for_citations(self, draft_path: str) -> str:
        """
        æƒææ•´ç¯‡è‰ç¨¿ï¼Œæ‰¾å‡ºæ‰€æœ‰éœ€è¦å¼•ç”¨çš„åœ°æ–¹ã€‚

        Args:
            draft_path: è‰ç¨¿æª”æ¡ˆè·¯å¾‘

        Returns:
            å®Œæ•´çš„å¼•ç”¨å»ºè­°å ±å‘Š
        """
        import os

        if not os.path.exists(draft_path):
            return f"âŒ File not found: {draft_path}"

        with open(draft_path, "r", encoding="utf-8") as f:
            content = f.read()

        # æŒ‰æ®µè½åˆ†æ
        paragraphs = re.split(r"\n\n+", content)
        all_claims: list[TextClaim] = []
        all_suggestions: list[CitationSuggestion] = []

        for para in paragraphs:
            if not para.strip() or para.startswith("#"):
                continue
            result = self.analyze_text(para, search_local=True, generate_queries=False)
            all_claims.extend([c for c in result.claims if c.needs_citation])
            all_suggestions.extend(result.local_suggestions)

        # å»é‡
        seen_pmids = set()
        unique_suggestions = []
        for sug in sorted(all_suggestions, key=lambda x: -x.relevance_score):
            if sug.pmid not in seen_pmids:
                seen_pmids.add(sug.pmid)
                unique_suggestions.append(sug)

        # ç”Ÿæˆ PubMed æœå°‹å»ºè­°
        pubmed_queries = self._generate_pubmed_queries(all_claims, unique_suggestions)

        final_result = CitationAnalysisResult(
            original_text=f"[Full draft: {draft_path}]",
            claims=all_claims,
            local_suggestions=unique_suggestions[:10],  # Top 10
            pubmed_search_queries=pubmed_queries,
            has_existing_citations=bool(self._extract_existing_citations(content)),
            existing_citations=self._extract_existing_citations(content),
            summary=f"Found {len(all_claims)} statements that may need citations.",
        )

        return final_result.to_markdown()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Private Methods
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _extract_existing_citations(self, text: str) -> list[str]:
        """æå–æ–‡å­—ä¸­å·²æœ‰çš„å¼•ç”¨"""
        # [[wikilink]] æ ¼å¼
        wikilinks = re.findall(r"\[\[([^\]]+)\]\]", text)
        # [PMID:xxx] æˆ– (PMID:xxx) æ ¼å¼
        pmid_refs = re.findall(r"[\[\(]PMID:(\d+)[\]\)]", text)
        # [1], [2] ç­‰æ•¸å­—å¼•ç”¨
        # num_refs = re.findall(r'\[(\d+)\]', text)

        return wikilinks + [f"PMID:{p}" for p in pmid_refs]

    def _analyze_text_claims(self, text: str) -> list[TextClaim]:
        """
        åˆ†ææ–‡å­—ä¸­çš„è²ç¨±ã€‚

        ä½¿ç”¨è¦å‰‡å¼æ–¹æ³•æª¢æ¸¬éœ€è¦å¼•ç”¨çš„é™³è¿°ã€‚
        """
        claims: list[TextClaim] = []

        # å°‡æ–‡å­—åˆ†æˆå¥å­
        sentences = re.split(r"[.!?ã€‚ï¼ï¼Ÿ]\s*", text)

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence or len(sentence) < 20:
                continue

            claim = self._classify_sentence(sentence)
            if claim:
                claims.append(claim)

        return claims

    def _classify_sentence(self, sentence: str) -> Optional[TextClaim]:
        """åˆ†é¡å–®ä¸€å¥å­"""
        sentence_lower = sentence.lower()

        # è·³éå·²æœ‰å¼•ç”¨çš„å¥å­
        if re.search(r"\[\[|\[PMID:|[\(\[]\d+[\)\]]", sentence):
            return None

        # çµ±è¨ˆæ•¸æ“šæ¨¡å¼
        if re.search(r"\d+\.?\d*\s*%|\d+/\d+|ç™¼ç”Ÿç‡|æ­»äº¡ç‡|ç››è¡Œç‡|prevalence|incidence|mortality", sentence_lower):
            return TextClaim(
                text=sentence,
                claim_type=ClaimType.STATISTICAL,
                key_terms=self._extract_key_terms(sentence),
                needs_citation=True,
                reason="Statistical claim requires source",
                suggested_search=self._generate_search_term(sentence, "epidemiology"),
            )

        # æ¯”è¼ƒè²ç¨±
        if re.search(r"æ¯”.*æ›´|å„ªæ–¼|åŠ£æ–¼|better|worse|superior|inferior|compared to|versus|vs\.?", sentence_lower):
            return TextClaim(
                text=sentence,
                claim_type=ClaimType.COMPARISON,
                key_terms=self._extract_key_terms(sentence),
                needs_citation=True,
                reason="Comparison claim requires evidence",
                suggested_search=self._generate_search_term(sentence, "comparison"),
            )

        # æŒ‡å¼•/å…±è­˜
        if re.search(r"guideline|æŒ‡å¼•|å»ºè­°|recommends?|consensus|å…±è­˜", sentence_lower):
            return TextClaim(
                text=sentence,
                claim_type=ClaimType.GUIDELINE,
                key_terms=self._extract_key_terms(sentence),
                needs_citation=True,
                reason="Guideline reference required",
                suggested_search=self._generate_search_term(sentence, "guideline"),
            )

        # æ©Ÿåˆ¶èªªæ˜
        if re.search(r"é€é|è—‰ç”±|mechanism|through|via|pathway|mediated", sentence_lower):
            return TextClaim(
                text=sentence,
                claim_type=ClaimType.MECHANISM,
                key_terms=self._extract_key_terms(sentence),
                needs_citation=True,
                reason="Mechanism claim needs supporting evidence",
                suggested_search=self._generate_search_term(sentence, "mechanism"),
            )

        # ç ”ç©¶é¡¯ç¤ºé¡
        if re.search(r"studies?|research|ç ”ç©¶|å ±å‘Š|report|evidence|suggests?|shows?|demonstrates?", sentence_lower):
            return TextClaim(
                text=sentence,
                claim_type=ClaimType.GENERAL,
                key_terms=self._extract_key_terms(sentence),
                needs_citation=True,
                reason="Claim about studies needs citation",
                suggested_search=self._generate_search_term(sentence, ""),
            )

        # å®šç¾©
        if re.search(r"å®šç¾©ç‚º|defined as|is defined|refers to", sentence_lower):
            return TextClaim(
                text=sentence,
                claim_type=ClaimType.DEFINITION,
                key_terms=self._extract_key_terms(sentence),
                needs_citation=True,
                reason="Definition should be cited",
                suggested_search=self._generate_search_term(sentence, "definition"),
            )

        return None

    def _extract_key_terms(self, text: str) -> list[str]:
        """æå–é—œéµè©"""
        # ç°¡å–®ç‰ˆï¼šæå–è‹±æ–‡å°ˆæœ‰åè©å’Œé†«å­¸è¡“èª
        # æœªä¾†å¯æ•´åˆ NER æˆ– MeSH è¡“èªåº«

        # ç§»é™¤å¸¸è¦‹åœç”¨è©
        stopwords = {
            "the", "a", "an", "is", "are", "was", "were", "be", "been", "being",
            "have", "has", "had", "do", "does", "did", "will", "would", "could",
            "should", "may", "might", "must", "shall", "can", "need", "dare",
            "to", "of", "in", "for", "on", "with", "at", "by", "from", "as",
            "into", "through", "during", "before", "after", "above", "below",
            "between", "under", "and", "but", "or", "nor", "so", "yet", "both",
            "either", "neither", "not", "only", "than", "that", "this", "these",
            "those", "such", "no", "very", "just", "also", "more", "most", "other",
        }

        # æå–è©å½™
        words = re.findall(r"\b[a-zA-Z]{3,}\b", text.lower())
        key_terms = [w for w in words if w not in stopwords]

        # å–å‰ 5 å€‹æœ€é•·çš„ï¼ˆå¯èƒ½æ˜¯å°ˆæœ‰åè©ï¼‰
        return sorted(set(key_terms), key=len, reverse=True)[:5]

    def _generate_search_term(self, sentence: str, suffix: str = "") -> str:
        """æ ¹æ“šå¥å­ç”Ÿæˆæœå°‹è©"""
        terms = self._extract_key_terms(sentence)
        base_query = " ".join(terms[:3])
        if suffix:
            return f"{base_query} {suffix}"
        return base_query

    def _search_local_for_claims(self, claims: list[TextClaim]) -> list[CitationSuggestion]:
        """åœ¨æœ¬åœ°æ–‡ç»åº«ä¸­æœå°‹èˆ‡è²ç¨±ç›¸é—œçš„æ–‡ç»"""
        suggestions: list[CitationSuggestion] = []

        # æ”¶é›†æ‰€æœ‰é—œéµè©
        all_terms: set[str] = set()
        for claim in claims:
            all_terms.update(claim.key_terms)

        if not all_terms:
            return suggestions

        # æœå°‹æœ¬åœ°æ–‡ç»
        for term in list(all_terms)[:10]:  # é™åˆ¶æœå°‹æ¬¡æ•¸
            results = self.ref_manager.search_local(term)

            for meta in results:
                pmid = meta.get("pmid", "")
                if not pmid:
                    continue

                # è¨ˆç®—ç›¸é—œæ€§
                title = meta.get("title", "").lower()
                abstract = meta.get("abstract", "").lower()
                matching_terms = [t for t in all_terms if t in title or t in abstract]

                if not matching_terms:
                    continue

                relevance_score = min(len(matching_terms) / len(all_terms), 1.0) if all_terms else 0

                suggestions.append(
                    CitationSuggestion(
                        pmid=pmid,
                        citation_key=meta.get("citation_key", pmid),
                        title=meta.get("title", "Unknown"),
                        relevance_score=relevance_score,
                        relevance_reason=f"Matches {len(matching_terms)} key terms",
                        matching_terms=matching_terms[:5],
                        source="local",
                    )
                )

        # å»é‡ä¸¦æŒ‰ç›¸é—œæ€§æ’åº
        seen: set[str] = set()
        unique: list[CitationSuggestion] = []
        for sug in sorted(suggestions, key=lambda x: -x.relevance_score):
            if sug.pmid not in seen:
                seen.add(sug.pmid)
                unique.append(sug)

        return unique

    def _generate_pubmed_queries(
        self, claims: list[TextClaim], local_suggestions: list[CitationSuggestion]
    ) -> list[str]:
        """ç”Ÿæˆ PubMed æœå°‹å»ºè­°"""
        queries: list[str] = []

        # å¾éœ€è¦å¼•ç”¨çš„è²ç¨±ä¸­æå–æœå°‹è©
        for claim in claims:
            if claim.needs_citation and claim.suggested_search:
                queries.append(claim.suggested_search)

        # å¦‚æœæœ¬åœ°æ‰¾ä¸åˆ°è¶³å¤ çš„æ–‡ç»ï¼Œå¼·åŒ–æœå°‹å»ºè­°
        if len(local_suggestions) < 3:
            # åˆä½µæ‰€æœ‰é—œéµè©åšä¸€å€‹ç¶œåˆæœå°‹
            all_terms = set()
            for claim in claims:
                all_terms.update(claim.key_terms[:3])
            if all_terms:
                queries.insert(0, " ".join(list(all_terms)[:5]))

        # å»é‡
        seen: set[str] = set()
        unique: list[str] = []
        for q in queries:
            q_lower = q.lower().strip()
            if q_lower and q_lower not in seen:
                seen.add(q_lower)
                unique.append(q)

        return unique[:5]  # æœ€å¤š 5 å€‹å»ºè­°

    def _generate_summary(
        self,
        claims: list[TextClaim],
        local_suggestions: list[CitationSuggestion],
        pubmed_queries: list[str],
    ) -> str:
        """ç”Ÿæˆç¸½çµ"""
        needs_citation = sum(1 for c in claims if c.needs_citation)

        parts = []

        if needs_citation == 0:
            parts.append("âœ… No statements found that require citations.")
        else:
            parts.append(f"ğŸ“ Found **{needs_citation}** statements that may need citations.")

        if local_suggestions:
            high_relevance = sum(1 for s in local_suggestions if s.relevance_score > 0.5)
            parts.append(f"ğŸ“š **{len(local_suggestions)}** potential matches in local library ({high_relevance} highly relevant).")
        else:
            parts.append("ğŸ“š No matches in local library.")

        if pubmed_queries:
            parts.append(f"ğŸ” **{len(pubmed_queries)}** suggested PubMed searches generated.")

        return " ".join(parts)
