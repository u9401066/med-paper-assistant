"""
PubMed Search Tools

search_literature, find_related_articles, find_citing_articles, search strategy
"""

import json
from mcp.server.fastmcp import FastMCP

from med_paper_assistant.infrastructure.external.pubmed.client import PubMedClient
from med_paper_assistant.infrastructure.services import StrategyManager
from med_paper_assistant.infrastructure.logging import setup_logger

logger = setup_logger()


def format_search_results(results: list, include_doi: bool = True) -> str:
    """Format search results for display."""
    if not results:
        return "No results found."
        
    if "error" in results[0]:
        return f"Error searching PubMed: {results[0]['error']}"
        
    formatted_output = f"Found {len(results)} results:\n\n"
    for i, paper in enumerate(results, 1):
        formatted_output += f"{i}. **{paper['title']}**\n"
        authors = paper.get('authors', [])
        formatted_output += f"   Authors: {', '.join(authors[:3])}{' et al.' if len(authors) > 3 else ''}\n"
        journal = paper.get('journal', 'Unknown Journal')
        year = paper.get('year', '')
        volume = paper.get('volume', '')
        pages = paper.get('pages', '')
        
        journal_info = f"{journal} ({year})"
        if volume:
            journal_info += f"; {volume}"
            if pages:
                journal_info += f": {pages}"
        formatted_output += f"   Journal: {journal_info}\n"
        formatted_output += f"   PMID: {paper.get('pmid', '')}"
        
        if include_doi and paper.get('doi'):
            formatted_output += f" | DOI: {paper['doi']}"
        if paper.get('pmc_id'):
            formatted_output += f" | PMC: {paper['pmc_id']} ğŸ“„"
        
        formatted_output += "\n"
        
        abstract = paper.get('abstract', '')
        if abstract:
            formatted_output += f"   Abstract: {abstract[:200]}...\n"
        formatted_output += "\n"
        
    return formatted_output


def register_pubmed_tools(mcp: FastMCP, searcher: PubMedClient, strategy_manager: StrategyManager):
    """Register PubMed search tools."""
    
    @mcp.tool()
    def configure_search_strategy(criteria_json: str) -> str:
        """
        Save a structured search strategy.
        
        Args:
            criteria_json: JSON string with keys: keywords (list), exclusions (list), 
                          article_types (list), min_sample_size (int), date_range (str).
        """
        try:
            criteria = json.loads(criteria_json)
            return strategy_manager.save_strategy(criteria)
        except Exception as e:
            return f"Error configuring strategy: {str(e)}"

    @mcp.tool()
    def get_search_strategy() -> str:
        """Get the currently saved search strategy."""
        strategy = strategy_manager.load_strategy()
        if not strategy:
            return "No strategy saved."
        return json.dumps(strategy.dict(), indent=2)

    @mcp.tool()
    def search_literature(
        query: str = "", 
        limit: int = 5, 
        min_year: int = None, 
        max_year: int = None,
        date_from: str = None,
        date_to: str = None,
        date_type: str = "edat",
        article_type: str = None, 
        strategy: str = "relevance", 
        use_saved_strategy: bool = False
    ) -> str:
        """
        Search for medical literature based on a query using PubMed.
        
        Args:
            query: The search query (e.g., "diabetes treatment guidelines"). 
                   Required if use_saved_strategy is False.
            limit: The maximum number of results to return.
            min_year: Optional minimum publication year (e.g., 2020).
            max_year: Optional maximum publication year.
            date_from: Precise start date in YYYY/MM/DD format (e.g., "2025/10/01").
                       More precise than min_year. If provided, overrides min_year.
            date_to: Precise end date in YYYY/MM/DD format (e.g., "2025/11/28").
                     More precise than max_year. If provided, overrides max_year.
            date_type: Which date field to search. Options:
                       - "edat" (default): Entrez date - when added to PubMed (best for NEW articles)
                       - "pdat": Publication date
                       - "mdat": Modification date
            article_type: Optional article type (e.g., "Review", "Clinical Trial", "Meta-Analysis").
            strategy: Search strategy ("recent", "most_cited", "relevance", "impact", "agent_decided"). 
                     Default is "relevance".
            use_saved_strategy: If True, uses the criteria from configure_search_strategy.
        """
        logger.info(f"Searching literature: query='{query}', limit={limit}, strategy='{strategy}'")
        try:
            min_sample_size = None
            
            if use_saved_strategy:
                saved_criteria = strategy_manager.load_strategy()
                if saved_criteria:
                    query = strategy_manager.build_pubmed_query(saved_criteria)
                    min_sample_size = saved_criteria.min_sample_size
                    logger.info(f"Using saved strategy. Generated query: {query}")
                else:
                    return "Error: No saved strategy found. Please use configure_search_strategy first."
            
            if not query:
                return "Error: Query is required unless use_saved_strategy is True and a strategy is saved."

            results = searcher.search(
                query, limit, min_year, max_year, 
                article_type, strategy,
                date_from=date_from, date_to=date_to, date_type=date_type
            )
            
            if min_sample_size:
                results = searcher.filter_results(results, min_sample_size)
                
            return format_search_results(results[:limit])
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return f"Error: {e}"

    @mcp.tool()
    def find_related_articles(pmid: str, limit: int = 5) -> str:
        """
        Find articles related to a given PubMed article.
        Uses PubMed's "Related Articles" feature to find similar papers.
        
        Args:
            pmid: PubMed ID of the source article.
            limit: Maximum number of related articles to return.
            
        Returns:
            List of related articles with details.
        """
        logger.info(f"Finding related articles for PMID: {pmid}")
        try:
            results = searcher.get_related_articles(pmid, limit)
            
            if not results:
                return f"No related articles found for PMID {pmid}."
            
            if "error" in results[0]:
                return f"Error finding related articles: {results[0]['error']}"
            
            output = f"ğŸ“š **Related Articles for PMID {pmid}** ({len(results)} found)\n\n"
            output += format_search_results(results)
            return output
        except Exception as e:
            logger.error(f"Find related articles failed: {e}")
            return f"Error: {e}"

    @mcp.tool()
    def find_citing_articles(pmid: str, limit: int = 10) -> str:
        """
        Find articles that cite a given PubMed article.
        Uses PubMed Central's citation data to find papers that reference this article.
        
        Args:
            pmid: PubMed ID of the source article.
            limit: Maximum number of citing articles to return.
            
        Returns:
            List of citing articles with details.
        """
        logger.info(f"Finding citing articles for PMID: {pmid}")
        try:
            results = searcher.get_citing_articles(pmid, limit)
            
            if not results:
                return f"No citing articles found for PMID {pmid}. (Article may not be indexed in PMC or has no citations yet.)"
            
            if "error" in results[0]:
                return f"Error finding citing articles: {results[0]['error']}"
            
            output = f"ğŸ“– **Articles Citing PMID {pmid}** ({len(results)} found)\n\n"
            output += format_search_results(results)
            return output
        except Exception as e:
            logger.error(f"Find citing articles failed: {e}")
            return f"Error: {e}"

    @mcp.tool()
    def generate_search_queries(
        topic: str,
        strategy: str = "comprehensive",
        include_mesh: bool = True,
        include_synonyms: bool = True,
        use_saved_strategy: bool = True
    ) -> str:
        """
        æ ¹æ“šä¸»é¡Œç”Ÿæˆå¤šçµ„æœå°‹èªæ³•ï¼Œä¾›ä¸¦è¡Œæœå°‹ä½¿ç”¨ã€‚
        
        é€™å€‹å·¥å…·è¿”å›å¤šå€‹æœå°‹ queriesï¼ŒAgent æ‡‰è©²**ä¸¦è¡Œå‘¼å«** search_literature
        å°æ¯å€‹ query åŸ·è¡Œæœå°‹ï¼Œç„¶å¾Œä½¿ç”¨ merge_search_results åˆä½µçµæœã€‚
        
        Args:
            topic: æœå°‹ä¸»é¡Œï¼ˆå¦‚ "remimazolam ICU sedation"ï¼‰
            strategy: æœå°‹ç­–ç•¥
                - "comprehensive": å…¨é¢æœå°‹ï¼Œå¤šçµ„ä¸åŒè§’åº¦çš„ queries
                - "focused": ç²¾ç¢ºæœå°‹ï¼Œè¼ƒå°‘ä½†æ›´ç²¾ç¢ºçš„ queries  
                - "exploratory": æ¢ç´¢æ€§æœå°‹ï¼ŒåŒ…å«æ›´å»£æ³›çš„ç›¸é—œæ¦‚å¿µ
            include_mesh: æ˜¯å¦åŒ…å« MeSH è©å½™çš„æœå°‹
            include_synonyms: æ˜¯å¦åŒ…å«åŒç¾©è©/åˆ¥å
            use_saved_strategy: æ˜¯å¦ä½¿ç”¨å·²å„²å­˜çš„æœå°‹ç­–ç•¥ï¼ˆdate_range, exclusions, article_typesï¼‰
            
        Returns:
            JSON æ ¼å¼çš„æœå°‹ç­–ç•¥ï¼ŒåŒ…å«å¤šå€‹ queries ä¾›ä¸¦è¡ŒåŸ·è¡Œ
        """
        logger.info(f"Generating search queries for topic: {topic}, strategy: {strategy}")
        
        # è¼‰å…¥å·²å„²å­˜çš„ç­–ç•¥è¨­å®š
        saved_strategy = None
        date_filter = ""
        exclusion_filter = ""
        article_type_filter = ""
        
        if use_saved_strategy:
            saved_strategy = strategy_manager.load_strategy()
            if saved_strategy:
                logger.info(f"Using saved strategy: {saved_strategy}")
                
                # è™•ç†æ—¥æœŸç¯„åœ
                if saved_strategy.date_range:
                    # æ”¯æ´æ ¼å¼: "2020-2024" æˆ– "5 years" æˆ– "last 10 years"
                    dr = saved_strategy.date_range.lower()
                    if "-" in dr and len(dr.split("-")) == 2:
                        parts = dr.split("-")
                        if parts[0].isdigit() and parts[1].isdigit():
                            date_filter = f" AND ({parts[0]}:{parts[1]}[dp])"
                    elif "year" in dr:
                        import re
                        match = re.search(r'(\d+)\s*year', dr)
                        if match:
                            years = int(match.group(1))
                            from datetime import datetime
                            current_year = datetime.now().year
                            start_year = current_year - years
                            date_filter = f" AND ({start_year}:{current_year}[dp])"
                
                # è™•ç†æ’é™¤è©
                if saved_strategy.exclusions:
                    exclusions = [f'NOT "{ex}"' for ex in saved_strategy.exclusions]
                    exclusion_filter = " " + " ".join(exclusions)
                
                # è™•ç†æ–‡ç« é¡å‹
                if saved_strategy.article_types:
                    types = [f'"{t}"[Publication Type]' for t in saved_strategy.article_types]
                    article_type_filter = f" AND ({' OR '.join(types)})"
        
        # è§£æä¸»é¡Œè©å½™
        words = topic.lower().split()
        
        # å»ºç«‹éæ¿¾å™¨å­—ä¸²ï¼ˆç”¨æ–¼è¿½åŠ åˆ°æ¯å€‹æŸ¥è©¢ï¼‰
        filters = f"{date_filter}{article_type_filter}{exclusion_filter}".strip()
        
        queries = []
        
        # Query 1: ç²¾ç¢ºæ¨™é¡Œæœå°‹
        base_q1 = f"({topic})[Title]"
        queries.append({
            "id": "q1_title",
            "query": f"{base_q1}{filters}" if filters else base_q1,
            "purpose": "ç²¾ç¢ºæ¨™é¡ŒåŒ¹é…",
            "expected": "é«˜ç›¸é—œæ€§ï¼Œè¼ƒå°‘çµæœ"
        })
        
        # Query 2: æ¨™é¡Œ/æ‘˜è¦æœå°‹
        base_q2 = f"({topic})[Title/Abstract]"
        queries.append({
            "id": "q2_tiab",
            "query": f"{base_q2}{filters}" if filters else base_q2,
            "purpose": "æ¨™é¡Œæˆ–æ‘˜è¦åŒ…å«é—œéµå­—",
            "expected": "ä¸­ç­‰ç›¸é—œæ€§ï¼Œé©é‡çµæœ"
        })
        
        # Query 3: çµ„åˆè©æœå°‹ï¼ˆç”¨ AND é€£æ¥ï¼‰
        and_query = " AND ".join(words)
        base_q3 = f"({and_query})"
        queries.append({
            "id": "q3_and",
            "query": f"{base_q3}{filters}" if filters else and_query,
            "purpose": "æ‰€æœ‰é—œéµå­—éƒ½å¿…é ˆå‡ºç¾",
            "expected": "è¼ƒåš´æ ¼çš„ç¯©é¸"
        })
        
        if strategy in ["comprehensive", "exploratory"]:
            # Query 4: éƒ¨åˆ†è©å½™æœå°‹ï¼ˆæ“´å±•ï¼‰
            if len(words) >= 2:
                # å–ä¸»è¦è©å½™çµ„åˆ
                main_word = words[0]
                context_words = " OR ".join(words[1:])
                base_q4 = f"({main_word} AND ({context_words}))"
                queries.append({
                    "id": "q4_partial",
                    "query": f"{base_q4}{filters}" if filters else f"{main_word} AND ({context_words})",
                    "purpose": "ä¸»è¦è©å½™ + ä»»ä¸€æƒ…å¢ƒè©",
                    "expected": "è¼ƒå¯¬é¬†çš„åŒ¹é…"
                })
        
        if include_mesh:
            # Query 5: MeSH è©å½™æœå°‹
            base_q5 = f"({topic})[MeSH Terms]"
            queries.append({
                "id": "q5_mesh",
                "query": f"{base_q5}{filters}" if filters else base_q5,
                "purpose": "ä½¿ç”¨ MeSH æ¨™æº–è©å½™",
                "expected": "é†«å­¸æ¦‚å¿µæ¨™æº–åŒ–åŒ¹é…"
            })
        
        if strategy == "exploratory":
            # Query 6: ç›¸é—œæ¦‚å¿µæ“´å±•
            # é€™è£¡å¯ä»¥åŠ å…¥æ›´å¤šé ˜åŸŸçŸ¥è­˜
            base_q6 = f"({words[0]})[Title] AND review[Publication Type]"
            queries.append({
                "id": "q6_broad",
                "query": f"{base_q6}{date_filter}{exclusion_filter}" if (date_filter or exclusion_filter) else base_q6,
                "purpose": "æ‰¾ç›¸é—œçš„ Review æ–‡ç« ",
                "expected": "äº†è§£é ˜åŸŸå…¨è²Œ"
            })
        
        # æ§‹å»ºçµæœ
        result = {
            "topic": topic,
            "strategy": strategy,
            "queries_count": len(queries),
            "queries": queries,
            "instruction": "è«‹ä¸¦è¡Œå‘¼å« search_literature å°æ¯å€‹ query åŸ·è¡Œæœå°‹ï¼Œ" +
                          "ç„¶å¾Œå‘¼å« merge_search_results åˆä½µçµæœã€‚",
            "example": {
                "parallel_calls": [
                    f"search_literature(query=\"{q['query']}\", limit=20)" 
                    for q in queries[:2]
                ] + ["..."]
            }
        }
        
        # åŠ å…¥å·²æ‡‰ç”¨çš„ç­–ç•¥è³‡è¨Š
        if saved_strategy:
            result["applied_strategy"] = {
                "date_range": saved_strategy.date_range or "not set",
                "exclusions": saved_strategy.exclusions or [],
                "article_types": saved_strategy.article_types or [],
                "note": "å·²å„²å­˜çš„æœå°‹ç­–ç•¥å·²è‡ªå‹•æ•´åˆåˆ°æŸ¥è©¢ä¸­"
            }
        else:
            result["applied_strategy"] = None
            result["tip"] = "å¯ä½¿ç”¨ configure_search_strategy è¨­å®šæ—¥æœŸç¯„åœã€æ’é™¤è©ç­‰ï¼Œä¸‹æ¬¡ç”ŸæˆæŸ¥è©¢æ™‚æœƒè‡ªå‹•å¥—ç”¨"
        
        return json.dumps(result, indent=2, ensure_ascii=False)

    @mcp.tool()
    def merge_search_results(results_json: str) -> str:
        """
        åˆä½µå¤šå€‹æœå°‹çµæœä¸¦å»é‡ã€‚
        
        åœ¨ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹ search_literature å¾Œï¼Œä½¿ç”¨æ­¤å·¥å…·åˆä½µçµæœã€‚
        
        Args:
            results_json: JSON æ ¼å¼çš„æœå°‹çµæœé™£åˆ—ï¼Œæ¯å€‹å…ƒç´ åŒ…å«ï¼š
                - query_id: æœå°‹ IDï¼ˆå°æ‡‰ generate_search_queries è¿”å›çš„ idï¼‰
                - pmids: PMID åˆ—è¡¨
                
                ä¾‹å¦‚ï¼š
                [
                    {"query_id": "q1_title", "pmids": ["12345", "67890"]},
                    {"query_id": "q2_tiab", "pmids": ["67890", "11111"]}
                ]
                
        Returns:
            åˆä½µå¾Œçš„çµæœï¼ŒåŒ…å«å»é‡å¾Œçš„ PMID åˆ—è¡¨å’Œä¾†æºåˆ†æ
        """
        logger.info("Merging search results")
        
        try:
            results = json.loads(results_json)
        except json.JSONDecodeError as e:
            return f"Error: Invalid JSON format - {e}"
        
        # æ”¶é›†æ‰€æœ‰ PMID å’Œä¾†æº
        pmid_sources = {}  # pmid -> [source_ids]
        all_pmids = []
        
        for result in results:
            query_id = result.get("query_id", "unknown")
            pmids = result.get("pmids", [])
            
            for pmid in pmids:
                pmid = str(pmid).strip()
                if pmid not in pmid_sources:
                    pmid_sources[pmid] = []
                    all_pmids.append(pmid)
                pmid_sources[pmid].append(query_id)
        
        # åˆ†æçµæœ
        multi_source = {pmid: sources for pmid, sources in pmid_sources.items() if len(sources) > 1}
        single_source = {pmid: sources[0] for pmid, sources in pmid_sources.items() if len(sources) == 1}
        
        # æŒ‰ä¾†æºåˆ†çµ„
        by_query = {}
        for result in results:
            query_id = result.get("query_id", "unknown")
            by_query[query_id] = len(result.get("pmids", []))
        
        output = {
            "total_unique": len(all_pmids),
            "total_with_duplicates": sum(by_query.values()),
            "duplicates_removed": sum(by_query.values()) - len(all_pmids),
            "by_query": by_query,
            "appeared_in_multiple_queries": {
                "count": len(multi_source),
                "pmids": list(multi_source.keys())[:10],  # åªé¡¯ç¤ºå‰ 10 å€‹
                "note": "é€™äº›æ–‡ç»è¢«å¤šå€‹æœå°‹ç­–ç•¥æ‰¾åˆ°ï¼Œå¯èƒ½æ›´ç›¸é—œ"
            },
            "unique_pmids": all_pmids,
            "next_step": "ä½¿ç”¨ save_reference(pmid=...) å„²å­˜æ„Ÿèˆˆè¶£çš„æ–‡ç»ï¼Œ" +
                        "æˆ–ä½¿ç”¨ get_reference_details(pmid=...) å–å¾—è©³ç´°è³‡è¨Š"
        }
        
        return json.dumps(output, indent=2, ensure_ascii=False)
