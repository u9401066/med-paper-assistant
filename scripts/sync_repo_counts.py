#!/usr/bin/env python3
"""
Repo Count Synchroniser â€” dynamically count metrics and sync into documentation.

Counts:
  - MCP tools (via AST parse of @mcp.tool() decorators)
  - Skills (.claude/skills/* directories)
  - Prompt workflows (.github/prompts/*.prompt.md)
  - Agents (.github/agents/*.agent.md)
  - Pre-commit hooks (.pre-commit-config.yaml  "- id:" lines)
  - Quality hooks (from AGENTS.md Hook æ¶æ§‹ table heading)
  - Pipeline phases (11 â€” semantic constant)

Modes:
  --check  : CI mode â€” exit 1 if any doc is stale (default)
  --fix    : Auto-update all documentation files
  --json   : Print counts as JSON and exit
  --verbose: Show details during check

Usage:
  uv run python scripts/sync_repo_counts.py --check
  uv run python scripts/sync_repo_counts.py --fix
  uv run python scripts/sync_repo_counts.py --json
"""

from __future__ import annotations

import ast
import io
import json
import os
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional


# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ROOT = Path(__file__).resolve().parent.parent
SRC = ROOT / "src" / "med_paper_assistant"
TOOLS_DIR = SRC / "interfaces" / "mcp" / "tools"

# External MCP counts (not in our codebase â€” maintained manually)
EXTERNAL_MCP = {
    "pubmed-search": 37,
    "cgu": 13,
}


# â”€â”€ Data Classes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@dataclass
class RepoCounts:
    """All dynamically counted repo metrics."""

    # mdpaper tool counts per module
    tool_groups: dict[str, int] = field(default_factory=dict)
    mdpaper_total: int = 0

    # External MCP
    pubmed_tools: int = EXTERNAL_MCP["pubmed-search"]
    cgu_tools: int = EXTERNAL_MCP["cgu"]

    # Derived
    total_tools: int = 0

    # Other counts
    skills: int = 0
    prompts: int = 0
    agents: int = 0
    precommit_hooks: int = 0
    quality_hooks: int = 0
    quality_hooks_code_enforced: int = 0
    quality_hooks_agent_driven: int = 0

    # Constants (semantic â€” don't auto-count)
    phases: int = 11
    mcp_servers: int = 3


# â”€â”€ Counting Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def count_mcp_tools() -> dict[str, int]:
    """Count @mcp.tool() decorators per group using AST (ignores docstrings)."""
    groups: dict[str, int] = {}
    skip_dirs = {"_shared", "__pycache__"}

    for py_file in sorted(TOOLS_DIR.rglob("*.py")):
        if py_file.name == "__init__.py":
            continue
        if any(sd in py_file.parts for sd in skip_dirs):
            continue

        group = py_file.parent.name
        content = py_file.read_text(encoding="utf-8")
        tree = ast.parse(content)

        count = 0
        for node in ast.walk(tree):
            if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                continue
            for dec in node.decorator_list:
                if isinstance(dec, ast.Call) and isinstance(dec.func, ast.Attribute):
                    if dec.func.attr == "tool":
                        count += 1

        if count > 0:
            groups[group] = groups.get(group, 0) + count

    return groups


def count_dir_entries(directory: Path, pattern: str = "*") -> int:
    """Count matching entries in a directory."""
    if not directory.exists():
        return 0
    return len(list(directory.glob(pattern)))


def count_skill_dirs() -> int:
    """Count skill directories under .claude/skills/."""
    skills_dir = ROOT / ".claude" / "skills"
    if not skills_dir.exists():
        return 0
    return len([d for d in skills_dir.iterdir() if d.is_dir()])


def count_precommit_hooks() -> int:
    """Count '- id:' entries in .pre-commit-config.yaml."""
    config = ROOT / ".pre-commit-config.yaml"
    if not config.exists():
        return 0
    content = config.read_text(encoding="utf-8")
    return len(re.findall(r"^\s+- id:", content, re.MULTILINE))


def parse_hook_counts_from_agents() -> tuple[int, int, int]:
    """Parse hook counts from AGENTS.md heading pattern.

    Returns (total, code_enforced, agent_driven).
    """
    agents_md = ROOT / "AGENTS.md"
    if not agents_md.exists():
        return 0, 0, 0
    content = agents_md.read_text(encoding="utf-8")
    m = re.search(
        r"Hook æ¶æ§‹[ï¼ˆ(](\d+)\s*checks\s*[â€”â€“-]+\s*(\d+)\s*Code-Enforced\s*/\s*(\d+)\s*Agent-Driven[ï¼‰)]",
        content,
    )
    if m:
        return int(m.group(1)), int(m.group(2)), int(m.group(3))
    return 0, 0, 0


def gather_counts() -> RepoCounts:
    """Gather all counts from the repo."""
    counts = RepoCounts()

    # MCP tools
    counts.tool_groups = count_mcp_tools()
    counts.mdpaper_total = sum(counts.tool_groups.values())
    counts.total_tools = counts.mdpaper_total + counts.pubmed_tools + counts.cgu_tools

    # Skills, Prompts, Agents
    counts.skills = count_skill_dirs()
    counts.prompts = count_dir_entries(ROOT / ".github" / "prompts", "*.prompt.md")
    counts.agents = count_dir_entries(ROOT / ".github" / "agents", "*.agent.md")

    # Pre-commit hooks
    counts.precommit_hooks = count_precommit_hooks()

    # Quality hooks (from AGENTS.md â€” single source of truth)
    total, ce, ad = parse_hook_counts_from_agents()
    counts.quality_hooks = total
    counts.quality_hooks_code_enforced = ce
    counts.quality_hooks_agent_driven = ad

    return counts


# â”€â”€ Document Replacement Rules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@dataclass
class ReplaceRule:
    """A pattern to find and replace in documentation."""

    file: Path
    pattern: str  # regex with group(s) to match the number
    replacement: str  # format string using counts
    description: str


def build_replace_rules(c: RepoCounts) -> list[ReplaceRule]:
    """Build all replacement rules from current counts."""
    rules: list[ReplaceRule] = []

    # â”€â”€ README.md and README.zh-TW.md â”€â”€

    for readme in [ROOT / "README.md", ROOT / "README.zh-TW.md"]:
        is_zh = "zh-TW" in readme.name

        # Tagline: "3 MCP Servers Â· ~131 Tools Â· 26 Skills Â· 14 Prompt Workflows"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"(\d+)\s*å€‹\s*MCP\s*Server\s*Â·\s*~?(\d+)\s*å€‹å·¥å…·\s*Â·\s*(\d+)\s*å€‹æŠ€èƒ½\s*Â·\s*(\d+)\s*å€‹\s*Prompt\s*å·¥ä½œæµ",
                f"{c.mcp_servers} å€‹ MCP Server Â· ~{c.total_tools} å€‹å·¥å…· Â· {c.skills} å€‹æŠ€èƒ½ Â· {c.prompts} å€‹ Prompt å·¥ä½œæµ",
                "zh tagline counts",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"(\d+)\s*MCP\s*Servers?\s*Â·\s*~?(\d+)\s*Tools?\s*Â·\s*(\d+)\s*Skills?\s*Â·\s*(\d+)\s*Prompt\s*Workflows?",
                f"{c.mcp_servers} MCP Servers Â· ~{c.total_tools} Tools Â· {c.skills} Skills Â· {c.prompts} Prompt Workflows",
                "en tagline counts",
            ))

        # Quality hooks line: "42 Quality Hooks" / "42 é …å“è³ªæª¢æŸ¥"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"(\d+)\s*é …å“è³ªæª¢æŸ¥",
                f"{c.quality_hooks} é …å“è³ªæª¢æŸ¥",
                "zh quality hook count",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"(\d+)\s*Quality\s*Hooks?",
                f"{c.quality_hooks} Quality Hooks",
                "en quality hook count",
            ))

        # Mermaid MCP subgraph: "MCP Servers (~131 tools)" / "MCP Serverï¼ˆ~131 å·¥å…·ï¼‰"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r'MCP\s*Server[ï¼ˆ(]~?\d+\s*å·¥å…·[ï¼‰)]',
                f'MCP Serverï¼ˆ~{c.total_tools} å·¥å…·ï¼‰',
                "zh mermaid MCP subgraph label",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r'MCP\s*Servers?\s*\(~?\d+\s*tools?\)',
                f'MCP Servers (~{c.total_tools} tools)',
                "en mermaid MCP subgraph label",
            ))

        # mdpaper node in mermaid: 'mdpaper["mdpaper<br/>81 tools<br/>'
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r'mdpaper\["mdpaper<br/>\d+\s*å·¥å…·',
                f'mdpaper["mdpaper<br/>{c.mdpaper_total} å·¥å…·',
                "zh mermaid mdpaper node",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r'mdpaper\["mdpaper<br/>\d+\s*tools',
                f'mdpaper["mdpaper<br/>{c.mdpaper_total} tools',
                "en mermaid mdpaper node",
            ))

        # pubmed node in mermaid
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r'pubmed\["pubmed-search<br/>\d+\s*å·¥å…·',
                f'pubmed["pubmed-search<br/>{c.pubmed_tools} å·¥å…·',
                "zh mermaid pubmed node",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r'pubmed\["pubmed-search<br/>\d+\s*tools',
                f'pubmed["pubmed-search<br/>{c.pubmed_tools} tools',
                "en mermaid pubmed node",
            ))

        # CGU node in mermaid
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r'cgu\["CGU<br/>\d+\s*å·¥å…·',
                f'cgu["CGU<br/>{c.cgu_tools} å·¥å…·',
                "zh mermaid CGU node",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r'cgu\["CGU<br/>\d+\s*tools',
                f'cgu["CGU<br/>{c.cgu_tools} tools',
                "en mermaid CGU node",
            ))

        # ASCII art box: "â”‚  81 tools" / "â”‚  81 å·¥å…·" for mdpaper
        word = "å·¥å…·" if is_zh else "tools"
        rules.append(ReplaceRule(
            readme,
            rf"(â”‚\s*ğŸ“\s*mdpaper\s*â”‚.*\nâ”‚)\s*\d+\s*{word}",
            rf"\g<1>  {c.mdpaper_total} {word}",
            f"{'zh' if is_zh else 'en'} ASCII mdpaper tools",
        ))

        # "All-in-one: ~131 tools in VS Code" / "ä¸€ç«™å¼ï¼š~131 å€‹å·¥å…·åœ¨ VS Code è£¡"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"ä¸€ç«™å¼[ï¼š:]\s*~?\d+\s*å€‹å·¥å…·",
                f"ä¸€ç«™å¼ï¼š~{c.total_tools} å€‹å·¥å…·",
                "zh all-in-one",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"All-in-one:\s*~?\d+\s*tools",
                f"All-in-one: ~{c.total_tools} tools",
                "en all-in-one",
            ))

        # "26 Skills + 14 Prompt Workflows" / "26 æŠ€èƒ½ + 14 Prompt å·¥ä½œæµ"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*æŠ€èƒ½\s*\+\s*\d+\s*Prompt\s*å·¥ä½œæµ",
                f"{c.skills} æŠ€èƒ½ + {c.prompts} Prompt å·¥ä½œæµ",
                "zh skills + prompts",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*Skills?\s*\+\s*\d+\s*Prompt\s*Workflows?",
                f"{c.skills} Skills + {c.prompts} Prompt Workflows",
                "en skills + prompts",
            ))

        # "26 Skills Â· 14 Prompts" in mermaid
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*æŠ€èƒ½\s*Â·\s*\d+\s*Prompts?",
                f"{c.skills} æŠ€èƒ½ Â· {c.prompts} Prompts",
                "zh mermaid skills prompts",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*Skills?\s*Â·\s*\d+\s*Prompts?",
                f"{c.skills} Skills Â· {c.prompts} Prompts",
                "en mermaid skills prompts",
            ))

        # "**26 Skills** covering" for README.md only
        if not is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\*\*\d+\s*Skills?\*\*\s*covering",
                f"**{c.skills} Skills** covering",
                "en bold skills covering",
            ))

        # mdpaper per-section headings: "### ğŸ“ Project Management (16 tools)"
        section_map = {
            "project": ("Project Management", "å°ˆæ¡ˆç®¡ç†"),
            "reference": ("Reference Management", "åƒè€ƒæ–‡ç»ç®¡ç†"),
            "draft": ("Draft & Editing", "è‰ç¨¿èˆ‡ç·¨è¼¯"),
            "validation": ("Validation", "é©—è­‰"),
            "analysis": ("Data Analysis", "è³‡æ–™åˆ†æ"),
            "review": ("Review & Audit", "å¯©æŸ¥èˆ‡å¯©è¨ˆ"),
            "export": ("Export & Submission", "åŒ¯å‡ºèˆ‡æŠ•ç¨¿"),
        }
        for group_key, (en_name, zh_name) in section_map.items():
            group_count = c.tool_groups.get(group_key, 0)
            if is_zh:
                rules.append(ReplaceRule(
                    readme,
                    rf"###\s*\S+\s*{re.escape(zh_name)}[ï¼ˆ(]\d+\s*å·¥å…·[ï¼‰)]",
                    f"### {_section_emoji(group_key)} {zh_name}ï¼ˆ{group_count} å·¥å…·ï¼‰",
                    f"zh {group_key} section heading",
                ))
            else:
                rules.append(ReplaceRule(
                    readme,
                    rf"###\s*\S+\s*{re.escape(en_name)}\s*\(\d+\s*tools?\)",
                    f"### {_section_emoji(group_key)} {en_name} ({group_count} tools)",
                    f"en {group_key} section heading",
                ))

        # Summary table: "mdpaper (81) + pubmed-search (37) + CGU (13)"
        rules.append(ReplaceRule(
            readme,
            r"mdpaper\s*\(\d+\)\s*\+\s*pubmed-search\s*\(\d+\)\s*\+\s*CGU\s*\(\d+\)",
            f"mdpaper ({c.mdpaper_total}) + pubmed-search ({c.pubmed_tools}) + CGU ({c.cgu_tools})",
            f"{'zh' if is_zh else 'en'} MCP summary table",
        ))

        # "3 MCP Servers |" / "3 å€‹ MCP Server |"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\*\*\d+\s*å€‹\s*MCP\s*Server\*\*",
                f"**{c.mcp_servers} å€‹ MCP Server**",
                "zh bold MCP server count",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"\*\*\d+\s*MCP\s*Servers?\*\*",
                f"**{c.mcp_servers} MCP Servers**",
                "en bold MCP server count",
            ))

        # Pre-commit hooks count
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\*\*\d+\s*å€‹\s*pre-commit\s*hooks?\*\*",
                f"**{c.precommit_hooks} å€‹ pre-commit hooks**",
                "zh pre-commit count",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"\*\*\d+\s*pre-commit\s*hooks?\*\*",
                f"**{c.precommit_hooks} pre-commit hooks**",
                "en pre-commit count",
            ))

        # Pre-commit in table: "15 hooks"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*hooks?[ï¼ˆ(]ruff",
                f"{c.precommit_hooks} hooksï¼ˆruff",
                "zh pre-commit hooks table",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*hooks?\s*\(ruff",
                f"{c.precommit_hooks} hooks (ruff",
                "en pre-commit hooks table",
            ))

        # Tree view: "MCP server, 81 tools in 8 groups"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"MCP\s*Server[ï¼Œ,]\s*\d+\s*å·¥å…·åˆ†\s*\d+\s*å¤§é¡",
                f"MCP Serverï¼Œ{c.mdpaper_total} å·¥å…·åˆ† {len(c.tool_groups)} å¤§é¡",
                "zh tree view tools",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"MCP\s*server,\s*\d+\s*tools\s*in\s*\d+\s*groups?",
                f"MCP server, {c.mdpaper_total} tools in {len(c.tool_groups)} groups",
                "en tree view tools",
            ))

        # Tree view: pubmed-search and CGU lines
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"PubMed/PMC/CORE\s*æœå°‹[ï¼ˆ(]\d+\s*å·¥å…·[ï¼‰)]",
                f"PubMed/PMC/CORE æœå°‹ï¼ˆ{c.pubmed_tools} å·¥å…·ï¼‰",
                "zh tree pubmed",
            ))
            rules.append(ReplaceRule(
                readme,
                r"å‰µæ„ç™¼æƒ³[ï¼ˆ(]\d+\s*å·¥å…·[ï¼‰)]",
                f"å‰µæ„ç™¼æƒ³ï¼ˆ{c.cgu_tools} å·¥å…·ï¼‰",
                "zh tree CGU",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"PubMed/PMC/CORE\s*search\s*\(\d+\s*tools?\)",
                f"PubMed/PMC/CORE search ({c.pubmed_tools} tools)",
                "en tree pubmed",
            ))
            rules.append(ReplaceRule(
                readme,
                r"Creative\s*generation\s*\(\d+\s*tools?\)",
                f"Creative generation ({c.cgu_tools} tools)",
                "en tree CGU",
            ))

        # Table row counts: "| 81 |" for mdpaper, "| 14 |" for Prompts, "| 26 |" for Skills
        # mdpaper row: match "Core MCP Server" or "æ ¸å¿ƒ MCP Server" context
        rules.append(ReplaceRule(
            readme,
            rf"((?:Core|æ ¸å¿ƒ)\s*MCP\s*Server\s*\|\s*)\d+",
            rf"\g<1>{c.mdpaper_total}",
            f"{'zh' if is_zh else 'en'} table mdpaper tools",
        ))
        # Prompts row: "Prompt Files" context
        rules.append(ReplaceRule(
            readme,
            r"(Prompt\s*Files?\s*\|\s*)\d+",
            rf"\g<1>{c.prompts}",
            f"{'zh' if is_zh else 'en'} table prompts count",
        ))

        # Prompt tree: "14 Prompt workflow files" / "14 å€‹ Prompt å·¥ä½œæµ"
        if is_zh:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*å€‹\s*Prompt\s*å·¥ä½œæµ",
                f"{c.prompts} å€‹ Prompt å·¥ä½œæµ",
                "zh prompt tree",
            ))
        else:
            rules.append(ReplaceRule(
                readme,
                r"\d+\s*Prompt\s*workflow\s*files?",
                f"{c.prompts} Prompt workflow files",
                "en prompt tree",
            ))

    # â”€â”€ ARCHITECTURE.md â”€â”€

    arch = ROOT / "ARCHITECTURE.md"
    if arch.exists():
        rules.append(ReplaceRule(
            arch,
            r"æä¾›\s*\d+\s*å€‹\s*tools",
            f"æä¾› {c.mdpaper_total} å€‹ tools",
            "ARCHITECTURE mdpaper tool count",
        ))
        rules.append(ReplaceRule(
            arch,
            r"Hook æ¶æ§‹[ï¼ˆ(]\d+\s*checks\s*[â€”â€“-]+\s*\d+\s*Code-Enforced\s*/\s*\d+\s*Agent-Driven[ï¼‰)]",
            f"Hook æ¶æ§‹ï¼ˆ{c.quality_hooks} checks â€” {c.quality_hooks_code_enforced} Code-Enforced / {c.quality_hooks_agent_driven} Agent-Drivenï¼‰",
            "ARCHITECTURE hook heading",
        ))
        rules.append(ReplaceRule(
            arch,
            r"è¿½è¹¤\s*\d+\s*å€‹\s*Hook",
            f"è¿½è¹¤ {c.quality_hooks} å€‹ Hook",
            "ARCHITECTURE hook tracking count",
        ))
        rules.append(ReplaceRule(
            arch,
            r"Copilot\s*Skills[ï¼ˆ(]\d+\s*å€‹[ï¼‰)]",
            f"Copilot Skillsï¼ˆ{c.skills} å€‹ï¼‰",
            "ARCHITECTURE skills count",
        ))
        rules.append(ReplaceRule(
            arch,
            r"Copilot\s*Prompts[ï¼ˆ(]\d+\s*å€‹[ï¼‰)]",
            f"Copilot Promptsï¼ˆ{c.prompts} å€‹ï¼‰",
            "ARCHITECTURE prompts count",
        ))

    # â”€â”€ copilot-instructions.md (both .github/ and vscode-extension/) â”€â”€

    for ci_path in [
        ROOT / ".github" / "copilot-instructions.md",
        ROOT / "vscode-extension" / "copilot-instructions.md",
    ]:
        if not ci_path.exists():
            continue

        # Header: "## MCP Serverï¼ˆ89 tools, ..."
        rules.append(ReplaceRule(
            ci_path,
            r"MCP\s*Server[ï¼ˆ(]\d+\s*tools",
            f"MCP Serverï¼ˆ{c.mdpaper_total} tools",
            f"copilot-instructions MCP header ({ci_path.parent.name})",
        ))

        # Hook heading
        rules.append(ReplaceRule(
            ci_path,
            r"Hook æ¶æ§‹[ï¼ˆ(]\d+\s*checks\s*[â€”â€“-]+\s*\d+\s*Code-Enforced\s*/\s*\d+\s*Agent-Driven[ï¼‰)]",
            f"Hook æ¶æ§‹ï¼ˆ{c.quality_hooks} checks â€” {c.quality_hooks_code_enforced} Code-Enforced / {c.quality_hooks_agent_driven} Agent-Drivenï¼‰",
            f"copilot-instructions hook heading ({ci_path.parent.name})",
        ))

        # Module breakdown table rows: match "| group/ " then capture spaces and "| N"
        for group_key in ["project", "reference", "draft", "validation", "analysis", "review", "export"]:
            group_count = c.tool_groups.get(group_key, 0)
            rules.append(ReplaceRule(
                ci_path,
                rf"(\|\s*{group_key}/\s*\|\s*)\d+",
                rf"\g<1>{group_count}",
                f"copilot-instructions {group_key} count ({ci_path.parent.name})",
            ))

    # â”€â”€ ROADMAP.md â”€â”€

    roadmap = ROOT / "ROADMAP.md"
    if roadmap.exists():
        rules.append(ReplaceRule(
            roadmap,
            r"\d+\s*å€‹å“è³ªæª¢æŸ¥",
            f"{c.quality_hooks} å€‹å“è³ªæª¢æŸ¥",
            "ROADMAP quality check count",
        ))

    # â”€â”€ CONSTITUTION.md â”€â”€

    constitution = ROOT / "CONSTITUTION.md"
    if constitution.exists():
        rules.append(ReplaceRule(
            constitution,
            r"\d+\s*å€‹å“è³ªæª¢æŸ¥",
            f"{c.quality_hooks} å€‹å“è³ªæª¢æŸ¥",
            "CONSTITUTION quality check count",
        ))
        rules.append(ReplaceRule(
            constitution,
            r"\d+/\d+\s*Code-Enforced",
            f"{c.quality_hooks_code_enforced}/{c.quality_hooks} Code-Enforced",
            "CONSTITUTION code-enforced ratio",
        ))

    # â”€â”€ AGENTS.md â”€â”€

    agents_md = ROOT / "AGENTS.md"
    if agents_md.exists():
        # L1 hooks line
        rules.append(ReplaceRule(
            agents_md,
            r"\d+\s*å€‹å“è³ªæª¢æŸ¥[ï¼ˆ(]\d+\s*Code-Enforced\s*/\s*\d+\s*Agent-Driven[ï¼‰)]",
            f"{c.quality_hooks} å€‹å“è³ªæª¢æŸ¥ï¼ˆ{c.quality_hooks_code_enforced} Code-Enforced / {c.quality_hooks_agent_driven} Agent-Drivenï¼‰",
            "AGENTS.md L1 hooks detail",
        ))
        # Hook heading (already in co-pilot instructions rules but AGENTS.md is separate)
        rules.append(ReplaceRule(
            agents_md,
            r"Hook æ¶æ§‹[ï¼ˆ(]\d+\s*checks\s*[â€”â€“-]+\s*\d+\s*Code-Enforced\s*/\s*\d+\s*Agent-Driven[ï¼‰)]",
            f"Hook æ¶æ§‹ï¼ˆ{c.quality_hooks} checks â€” {c.quality_hooks_code_enforced} Code-Enforced / {c.quality_hooks_agent_driven} Agent-Drivenï¼‰",
            "AGENTS.md hook heading",
        ))

    # â”€â”€ docs/auto-paper-guide.md â”€â”€
    # NOTE: auto-paper-guide.md uses "42 é …è‡ªå‹•å“è³ªæª¢æŸ¥ï¼ˆHook A-Dï¼‰"
    # which is the Agent-Driven subset (42), NOT total hooks (76).
    # This is intentional â€” do NOT auto-replace.

    return rules


def _section_emoji(group: str) -> str:
    """Return the emoji for a tool group section."""
    return {
        "project": "ğŸ“",
        "reference": "ğŸ“š",
        "draft": "âœï¸",
        "validation": "âœ…",
        "analysis": "ğŸ“Š",
        "review": "ğŸ”",
        "export": "ğŸ“„",
    }.get(group, "ğŸ“¦")


# â”€â”€ Apply / Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def apply_rules(rules: list[ReplaceRule], *, fix: bool, verbose: bool) -> list[str]:
    """Apply all replacement rules. Returns list of issues found."""
    issues: list[str] = []
    files_modified: set[Path] = set()

    # Group rules by file for efficiency
    by_file: dict[Path, list[ReplaceRule]] = {}
    for rule in rules:
        by_file.setdefault(rule.file, []).append(rule)

    for fpath, file_rules in by_file.items():
        if not fpath.exists():
            issues.append(f"âš ï¸  File not found: {fpath.relative_to(ROOT)}")
            continue

        content = fpath.read_text(encoding="utf-8")
        new_content = content

        for rule in file_rules:
            matches = list(re.finditer(rule.pattern, new_content))
            if not matches:
                if verbose:
                    print(f"  â„¹ï¸  No match for [{rule.description}] in {fpath.relative_to(ROOT)}")
                continue

            for match in matches:
                old_text = match.group(0)
                # Build replacement (handle backrefs)
                new_text = re.sub(rule.pattern, rule.replacement, old_text)
                if old_text != new_text:
                    issues.append(
                        f"{'ğŸ”§' if fix else 'âŒ'} {fpath.relative_to(ROOT)}: "
                        f"[{rule.description}] {old_text!r} â†’ {new_text!r}"
                    )
                    if fix:
                        new_content = new_content.replace(old_text, new_text, 1)
                        files_modified.add(fpath)

        if fix and fpath in files_modified:
            fpath.write_text(new_content, encoding="utf-8")

    if fix and files_modified:
        print(f"\nâœ… Updated {len(files_modified)} file(s):")
        for f in sorted(files_modified):
            print(f"   {f.relative_to(ROOT)}")

    return issues


# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def main() -> int:
    # Ensure UTF-8 output on Windows
    if os.name == "nt":
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

    args = sys.argv[1:]
    fix_mode = "--fix" in args
    json_mode = "--json" in args
    verbose = "--verbose" in args or "-v" in args

    counts = gather_counts()

    if json_mode:
        data = {
            "mdpaper_tools": {
                "total": counts.mdpaper_total,
                "groups": counts.tool_groups,
            },
            "external_mcp": {
                "pubmed-search": counts.pubmed_tools,
                "cgu": counts.cgu_tools,
            },
            "total_tools": counts.total_tools,
            "skills": counts.skills,
            "prompts": counts.prompts,
            "agents": counts.agents,
            "precommit_hooks": counts.precommit_hooks,
            "quality_hooks": {
                "total": counts.quality_hooks,
                "code_enforced": counts.quality_hooks_code_enforced,
                "agent_driven": counts.quality_hooks_agent_driven,
            },
            "mcp_servers": counts.mcp_servers,
            "phases": counts.phases,
        }
        print(json.dumps(data, indent=2))
        return 0

    # Print summary
    print("ğŸ“Š Repository Counts (dynamic)")
    print("=" * 50)
    print(f"  MCP Tools (mdpaper) : {counts.mdpaper_total}")
    for g in sorted(counts.tool_groups):
        print(f"    {g + '/':<14s}: {counts.tool_groups[g]}")
    print(f"  pubmed-search       : {counts.pubmed_tools} (external)")
    print(f"  CGU                 : {counts.cgu_tools} (external)")
    print(f"  Total tools         : ~{counts.total_tools}")
    print(f"  Skills              : {counts.skills}")
    print(f"  Prompts             : {counts.prompts}")
    print(f"  Agents              : {counts.agents}")
    print(f"  Pre-commit hooks    : {counts.precommit_hooks}")
    print(f"  Quality hooks       : {counts.quality_hooks} ({counts.quality_hooks_code_enforced} CE / {counts.quality_hooks_agent_driven} AD)")
    print(f"  Pipeline phases     : {counts.phases}")
    print()

    rules = build_replace_rules(counts)

    if fix_mode:
        print("ğŸ”§ Fix mode â€” updating documentation...")
        issues = apply_rules(rules, fix=True, verbose=verbose)
    else:
        print("ğŸ” Check mode â€” scanning for stale counts...")
        issues = apply_rules(rules, fix=False, verbose=verbose)

    stale = [i for i in issues if i.startswith("âŒ")]
    fixed = [i for i in issues if i.startswith("ğŸ”§")]
    warnings = [i for i in issues if i.startswith("âš ï¸")]

    if verbose or stale or fixed:
        print()
        for issue in issues:
            print(f"  {issue}")

    if fix_mode:
        if fixed:
            print(f"\nğŸ”§ Fixed {len(fixed)} stale count(s).")
        else:
            print("\nâœ… All counts already up to date.")
        return 0
    else:
        if stale:
            print(f"\nâŒ {len(stale)} stale count(s) found. Run with --fix to update.")
            return 1
        else:
            print("\nâœ… All documentation counts are in sync.")
            return 0


if __name__ == "__main__":
    sys.exit(main())
